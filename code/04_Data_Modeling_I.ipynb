{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5277401-f00d-45e5-9ca0-8ebf7fa85666",
   "metadata": {},
   "source": [
    "# Predicting All-NBA Team and Player Salaries - Predicting All-NBA Team and Salary\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4565d24-93c6-4976-bc52-1b24dd3e4b4f",
   "metadata": {},
   "source": [
    "In this notebook, we will build upon the groundwork laid by our webscraping, data cleaning, and exploratory data analysis. Our cleaned data now contains over 80 features, including player statistic (advanced, totals, and per-game), salary cap information, and team payroll data. With this, our objective is twofold:\n",
    "\n",
    "1. <u>**All-NBA Team**</u>: First we will construct multiple regression models to predict voter share, which will ultimately enable us to discern the All-NBA Teams. By employing various regression techniques, we can gain valuable insights into the factors that influence the voters' decisions, helping us understand what distinguishes an All-NBA player from others. \n",
    "2. <u>**Salary**</u>: We will then also use regression modeling to predict player salaries, training on the intricate relationship between player performance, individual statistics, and their contracts. \n",
    "\n",
    "This process will involve trial and error as well as the application of GridSearch and RandomizedSearch techniques to fine-tune our models.\n",
    "\n",
    "At the end of our analysis, we hope to unravel the complexities of the NBA landscape, discovering patterns and associations that govern player recognition in All-NBA Teams and their financial remuneration. These insights will inform decision-making processes and aid in the evaluation of player performance and compensation within the competitive realm of professional basketball.\n",
    "\n",
    "Further detailed notebooks on the various segments of this project can be found at the following: \n",
    "- [01_Data_Acquisition](./01_Data_Acquisition.ipynb)\n",
    "- [02_Data_Cleaning](./02_Data_Cleaning.ipynb)\n",
    "- [03_Preliminary_EDA](./03_Preliminary_EDA.ipynb)\n",
    "- [05_Data_Modeling_II](./05_Data_Modeling_II.ipynb)\n",
    "\n",
    "For more information on the background, a summary of methods, and findings, please see the associated [README](../README.md) for this analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5634183-6106-4c97-9484-e79d252bbf58",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616a53e9-1a2b-4e80-8e01-057a759cb8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "# Notebook was run with warnings enabled and any significant ones were addressed, remaining warnings are insignificant and \n",
    " # have been suppressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed35c3f-60ac-457c-97eb-4dea53d4b271",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report, RocCurveDisplay, roc_auc_score\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, BaggingClassifier, VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77c046e-a077-4276-a901-1c79b9f4b2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define baseline\n",
    "snowski.subreddit.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0406982-270b-41c3-9bd8-aaf5ee5b9836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline that tests b/t CVEC and TVEC transformers and an estimator\n",
    "pipe_log = Pipeline([\n",
    "                 ('vec', None),\n",
    "                 ('logr', LogisticRegression(solver = 'liblinear', max_iter=1000))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78783fa0-1253-46ff-a6cd-90b62931801b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16c662c-6451-4e6c-8597-bd20294822a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077bc93a-d564-433c-b583-d4d927e0fcf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59476b6-4c73-406b-8928-ce5521ac548d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb1bf60-08ca-4dc1-9fda-b28837020a1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac255f6-5b0c-4a4d-a9dd-7a469bedfe3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72edd29d-5a89-417a-92eb-0ab3694408c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37b2e51-6416-4212-b595-b1cb34651d78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac7dc8d-fd4b-4488-abc1-5204f0f4c9a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2872e0-968a-4bf9-8230-497d70a3a454",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea271b9e-80ae-48d9-8485-0c75cf4dc6d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf197f0e-801b-4f62-aa0c-ece5ffbae646",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
