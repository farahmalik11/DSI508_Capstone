{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5277401-f00d-45e5-9ca0-8ebf7fa85666",
   "metadata": {},
   "source": [
    "# Predicting All-NBA Team and Player Salaries - Predicting All-NBA Team and Salary\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4565d24-93c6-4976-bc52-1b24dd3e4b4f",
   "metadata": {},
   "source": [
    "In this notebook, we will build upon the groundwork laid by our webscraping, data cleaning, and exploratory data analysis. Our cleaned data now contains over 80 features, including player statistic (advanced, totals, and per-game), salary cap information, and team payroll data. With this, our objective is twofold:\n",
    "\n",
    "1. <u>**All-NBA Team**</u>: First we will construct multiple regression models to predict voter share, which will ultimately enable us to discern the All-NBA Teams. By employing various regression techniques, we can gain valuable insights into the factors that influence the voters' decisions, helping us understand what distinguishes an All-NBA player from others. \n",
    "2. <u>**Salary**</u>: We will then also use regression modeling to predict player salaries, training on the intricate relationship between player performance, individual statistics, and their contracts. \n",
    "\n",
    "This process will involve trial and error as well as the application of GridSearch and RandomizedSearch techniques to fine-tune our models.\n",
    "\n",
    "At the end of our analysis, we hope to unravel the complexities of the NBA landscape, discovering patterns and associations that govern player recognition in All-NBA Teams and their financial remuneration. These insights will inform decision-making processes and aid in the evaluation of player performance and compensation within the competitive realm of professional basketball.\n",
    "\n",
    "Further detailed notebooks on the various segments of this project can be found at the following: \n",
    "- [01_Data_Acquisition](./01_Data_Acquisition.ipynb)\n",
    "- [02_Data_Cleaning](./02_Data_Cleaning.ipynb)\n",
    "- [03_Preliminary_EDA](./03_Preliminary_EDA.ipynb)\n",
    "- [05_Data_Modeling_II](./05_Data_Modeling_II.ipynb)\n",
    "\n",
    "For more information on the background, a summary of methods, and findings, please see the associated [README](../README.md) for this analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5634183-6106-4c97-9484-e79d252bbf58",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ed35c3f-60ac-457c-97eb-4dea53d4b271",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestRegressor, ExtraTreesRegressor, BaggingRegressor, VotingRegressor, AdaBoostRegressor, GradientBoostingRegressor\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# LGBMRegressor\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XGBRegressor\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# from sklearn.compose import ColumnTransformer\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# from sklearn.neighbors import KNeighborsClassifier\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#import shap\n",
    "import streamlit as st\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV, ElasticNet\n",
    "from sklearn.svm import LinearSVR, SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, BaggingRegressor, VotingRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "# LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6c6b31f-d5cc-469b-96db-f2c6a34ba94f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/clean/stats_main.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/clean/stats_main.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77c046e-a077-4276-a901-1c79b9f4b2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define baseline\n",
    "snowski.subreddit.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61b11b0-75ab-47fe-ad18-a898ab274d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = snowski['text']\n",
    "y = snowski['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0406982-270b-41c3-9bd8-aaf5ee5b9836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline that tests b/t CVEC and TVEC transformers and an estimator\n",
    "pipe_log = Pipeline([\n",
    "                 ('vec', None),\n",
    "                 ('logr', LogisticRegression(solver = 'liblinear', max_iter=1000))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78783fa0-1253-46ff-a6cd-90b62931801b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16c662c-6451-4e6c-8597-bd20294822a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_svc = Pipeline([\n",
    "    ('vec', None),\n",
    "    ('svc', SVC())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077bc93a-d564-433c-b583-d4d927e0fcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pgrid_svc =[\n",
    "    {\n",
    "     'vec': [CountVectorizer()],\n",
    "     'vec__stop_words': [None], #tested english stopwords as well\n",
    "     'vec__max_features': [7000], #also tested 8000 \n",
    "     'vec__min_df': [3, 5],\n",
    "     'vec__max_df': [0.80], #tested 0.90 as well\n",
    "     'svc__C': np.linspace(0.0001, 2, 10),\n",
    "     #'svc__kernel': ['rbf','poly'],\n",
    "     'svc__degree' : [2]\n",
    "    },\n",
    "    {\n",
    "     'vec': [TfidfVectorizer()],\n",
    "     'vec__stop_words': [None],\n",
    "     'vec__max_features': [7000], \n",
    "     'vec__min_df': [3, 5],\n",
    "     'vec__max_df': [0.80],\n",
    "     'svc__C': np.linspace(0.0001, 2, 10),\n",
    "     #'svc__kernel': ['rbf','poly'],\n",
    "     'svc__degree' : [2]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59476b6-4c73-406b-8928-ce5521ac548d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "gs_svc = GridSearchCV(pipe_svc, pgrid_svc, n_jobs=25)\n",
    "gs_svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb1bf60-08ca-4dc1-9fda-b28837020a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for Accuracy Report\n",
    "preds_svc = gs_svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac255f6-5b0c-4a4d-a9dd-7a469bedfe3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'----------------- {b1}SVM w/ GridSearch{b0} ----------------')\n",
    "print(f'------------------ Train: {round(gs_svc.score(X_train, y_train),4)} -------------------')\n",
    "print(f'------------------- Test: {round(gs_svc.score(X_test, y_test),4)} -------------------')\n",
    "print('Best Params:', gs_svc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72edd29d-5a89-417a-92eb-0ab3694408c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Test RandomizedSearch for comparison in timing and outcome\n",
    "rs_svc = RandomizedSearchCV(pipe_svc, pgrid_svc, cv=5, n_iter=10, n_jobs=15)\n",
    "rs_svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37b2e51-6416-4212-b595-b1cb34651d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for Accuracy Report\n",
    "preds_svc_r = rs_svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac7dc8d-fd4b-4488-abc1-5204f0f4c9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'-------------- {b1}SVM w/ RandomizedSearch{b0} --------------')\n",
    "print(f'------------------- Train: {round(rs_svc.score(X_train, y_train),4)} -------------------')\n",
    "print(f'------------------- Test: {round(rs_svc.score(X_test, y_test),4)} --------------------')\n",
    "print('Best Params:', rs_svc.best_params_)\n",
    "\n",
    "# Randomized search computed faster and test score is slightly better - we will utilize RS more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2872e0-968a-4bf9-8230-497d70a3a454",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf197f0e-801b-4f62-aa0c-ece5ffbae646",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
