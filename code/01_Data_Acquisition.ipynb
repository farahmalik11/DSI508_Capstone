{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c707421a-e432-4de5-b058-3c1a78260914",
   "metadata": {},
   "source": [
    "# Predicting All-NBA Team and Player Salaries - Data Acquisition\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a1d413-5f90-4bdb-87f1-06a511bac557",
   "metadata": {},
   "source": [
    "This notebook launches our project by webscraping National Basketball Association (NBA) player and team data on salary and statistics (total, per-game, and advanced) from various basketball sites. Most of this data will come from popular statistics website ```Basketball-Reference```, while others is also sourced from ```HoopsHype``` and ```Wikipedia```. Additional data from Kaggle datasets may be used at a later time as needed.\n",
    "\n",
    "Using webscraping methods ```BeautifulSoup``` and ```Selenium```, we will start by saving a snapshot of the HTML page housing our desired statistics. We will then use those pages to inspect and pull the tables the interest into CSV's for further data cleaning and feature engineering. You will see that throughout this notebook we incorporate sleep times / rate limits between data pulling requests, this will prevent server overload and potential IP blocking, and will ensure respectful and responsible webscraping.\n",
    "\n",
    "For more information on the background, a summary of methods, and findings, please see the associated [README](../README.md) for this analysis. For further detailed notebooks on the different parts of the project see the following: \n",
    "- [02_Data_Cleaning_and_EDA]('./02_Data_Cleaning_and_EDA')\n",
    "- [03_Data_Modeling_I]('./03_Data_Modeling_I')\n",
    "- [04_Data_Modeling_II]('./04_Data_Modeling_II')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1755aa9e-f972-4578-bde5-0929a8c1dce4",
   "metadata": {},
   "source": [
    "### Contents\n",
    "- [1. Salary Data](#1.-Salary-Data)\n",
    "    - [I. Player Salary](#I.-Player-Salary)\n",
    "    - [II. Team Payroll](#II.-Team-Payroll)\n",
    "    - [III. Salary Caps](#III.-Salary-Caps)\n",
    "- [2. Statistics Data](#2.-Statistics-Data)\n",
    "    - [IV. Player Statistics](#IV.-Player-Statistics)\n",
    "    - [V. All-NBA Team Winners and Nominees](#V.-All-NBA-Team-Winners-and-Nominees)\n",
    "- [3. Additional Performance-Related Data](#3.-Additional-Performance-Related-Data)\n",
    "    - [VI. Team Rankings](#VI.-Team-Rankings)\n",
    "    - [VII. All-Star-Appearance](#VII.-All-Star-Appearance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05b1741b-d02d-4e69-9f10-ea536ed9ba12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "25301130-eea5-45a6-b2d6-283675cbdeee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-4.10.0-py3-none-any.whl (6.7 MB)\n",
      "     ---------------------------------------- 6.7/6.7 MB 8.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\farah\\anaconda3\\lib\\site-packages (from selenium) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\farah\\anaconda3\\lib\\site-packages (from selenium) (2023.5.7)\n",
      "Collecting trio~=0.17\n",
      "  Downloading trio-0.22.2-py3-none-any.whl (400 kB)\n",
      "     ------------------------------------- 400.2/400.2 kB 12.2 MB/s eta 0:00:00\n",
      "Collecting trio-websocket~=0.9\n",
      "  Downloading trio_websocket-0.10.3-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\farah\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\farah\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Collecting exceptiongroup>=1.0.0rc9\n",
      "  Downloading exceptiongroup-1.1.2-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\farah\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\farah\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: sniffio in c:\\users\\farah\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Collecting outcome\n",
      "  Downloading outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting wsproto>=0.14\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\farah\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\farah\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Collecting h11<1,>=0.9.0\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "     ---------------------------------------- 58.3/58.3 kB 3.0 MB/s eta 0:00:00\n",
      "Installing collected packages: outcome, h11, exceptiongroup, wsproto, trio, trio-websocket, selenium\n",
      "Successfully installed exceptiongroup-1.1.2 h11-0.14.0 outcome-1.2.0 selenium-4.10.0 trio-0.22.2 trio-websocket-0.10.3 wsproto-1.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d08b4e-f6ec-47c4-a414-0663f05affb9",
   "metadata": {},
   "source": [
    "### Define Years of Interest\n",
    "##### To be periodically updated to include latest available seasons. This will enable the model to remain robust and reflective of the most recent trends and patterns in the NBA.\n",
    "\n",
    "Note: Year variable may need to be manipulated by adding +1 when called to mirror which season the specific site is referring to. We are considering each year to refer to the the season _start_ date (e.g., 1991 will refer to the 1991-1992 season). Some sites, such as that showing team rankings, understandably will refer to the 1991 team ranking based on the season _end_ date (e.g., 1991 will refer to the 1990-1991 season). We will adjust the year variable accordingly in our loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3028c4a8-a856-4b06-a126-f108cdf2c491",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = list(range(1990,2023)) # stopping at 2022 which will be the 2022-23 season"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e90cd45-d523-455b-9c5e-47e7951ad53e",
   "metadata": {},
   "source": [
    "### Selenium Setup\n",
    "\n",
    "##### Several of the following sections ([Player Statistics](#V.-Player-Statistics), [Salary Caps](#VI.-Salary-Caps), [All-NBA Team Winners](#VII.-All-NBA-Team-Winners-and-Nominees)) will use the [Selenium](https://selenium-python.readthedocs.io/index.html) Python package to webscrape dynamic tables which render all rows using JavaScript after the page has loaded. To ensure smooth execution for other users, follow these steps if you wish to run the provided code:\n",
    "\n",
    "1. Install Selenium with ```pip install selenium```\n",
    "<br></br>\n",
    "2. Choose the web browser you intend to run this code on (different browsers require different drivers) and ensure that you have the latest version of the browser installed.\n",
    "<br></br>\n",
    "3. Download, extract, and save [Selenium webdriver](https://selenium-python.readthedocs.io/installation.html#drivers) for your chosen browser to the current ```code``` folder housing this notebook.\n",
    "    1. Perform the download, extract, save\n",
    "    2. Operationalize webdriver\n",
    "        1. <u>Method 1</u>: Specify location of driver in the cell below, for example: ```driver = webdriver.Edge(executable_path='c:\\User-Path\\msedgedriver.exe')```. Replace the following:\n",
    "            - ```Edge``` with the browser you installed the driver for, \n",
    "            - ```User-Path``` with the path where driver is saved, and \n",
    "            - ```msedgedriver.exe```  with the name of the extracted driver\n",
    "        2. <u>Method 2</u>: To **bypass** having to perform Method 1 with each use of the webdriver, consider adding the extracted webdriver to the Path variable on your machine (accessible via Advanced System Settings on your computer). In this case, do not update the ```driver = webdriver.Edge()``` code below, except for changing ```Edge``` to your preferred browser.\n",
    "<br></br>\n",
    "4. As new versions of browsers/webdrivers become available, **re-perform** Steps 2 & 3 above.\n",
    "\n",
    "By following these steps, you'll ensure that the provided code continues to work smoothly as you access the latest player statistics using Selenium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d41acc-a8ac-421c-93b1-435eea5307e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Edge()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1672c734-0e19-4e73-8edb-ff36deadd891",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **1. Salary Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8e8a98-c177-4b87-bfc3-819430657e55",
   "metadata": {
    "tags": []
   },
   "source": [
    "## I. Player Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4767c9c1-31eb-4d20-a79d-9998f46e2f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished writing 1990, waiting ... 5.83\n",
      "Finished writing 1991, waiting ... 4.62\n",
      "Finished writing 1992, waiting ... 4.06\n",
      "Finished writing 1993, waiting ... 4.44\n",
      "Finished writing 1994, waiting ... 5.88\n",
      "Finished writing 1995, waiting ... 5.49\n",
      "Finished writing 1996, waiting ... 5.65\n",
      "Finished writing 1997, waiting ... 4.89\n",
      "Finished writing 1998, waiting ... 5.32\n",
      "Finished writing 1999, waiting ... 5.05\n",
      "Finished writing 2000, waiting ... 4.71\n",
      "Finished writing 2001, waiting ... 4.59\n",
      "Finished writing 2002, waiting ... 4.67\n",
      "Finished writing 2003, waiting ... 5.13\n",
      "Finished writing 2004, waiting ... 5.83\n",
      "Finished writing 2005, waiting ... 4.45\n",
      "Finished writing 2006, waiting ... 5.16\n",
      "Finished writing 2007, waiting ... 4.99\n",
      "Finished writing 2008, waiting ... 4.06\n",
      "Finished writing 2009, waiting ... 4.93\n",
      "Finished writing 2010, waiting ... 5.68\n",
      "Finished writing 2011, waiting ... 4.07\n",
      "Finished writing 2012, waiting ... 5.81\n",
      "Finished writing 2013, waiting ... 5.18\n",
      "Finished writing 2014, waiting ... 4.18\n",
      "Finished writing 2015, waiting ... 4.73\n",
      "Finished writing 2016, waiting ... 4.07\n",
      "Finished writing 2017, waiting ... 4.82\n",
      "Finished writing 2018, waiting ... 4.1\n",
      "Finished writing 2019, waiting ... 5.26\n",
      "Finished writing 2020, waiting ... 4.43\n",
      "Finished writing 2021, waiting ... 4.29\n",
      "Finished writing 2022, waiting ... 5.0\n"
     ]
    }
   ],
   "source": [
    "for year in years:\n",
    "    sal_url = f'https://hoopshype.com/salaries/players/{year}-{year+1}/'\n",
    "    url = sal_url.format(year)\n",
    "    res = requests.get(url)\n",
    "    if res.status_code >= 200:\n",
    "        with open(\"webscraping/salary/{}.html\".format(year), \"w+\", encoding=\"utf-8\") as file:\n",
    "            file.write(res.text)\n",
    "            lag = np.random.uniform(4,6)\n",
    "            print(f'Finished writing {year}, waiting ... {round(lag,2)}')\n",
    "            time.sleep(lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f3744e5-28ec-40aa-b47e-04139ee1588c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished scraping 1990\n",
      "Finished scraping 1991\n",
      "Finished scraping 1992\n",
      "Finished scraping 1993\n",
      "Finished scraping 1994\n",
      "Finished scraping 1995\n",
      "Finished scraping 1996\n",
      "Finished scraping 1997\n",
      "Finished scraping 1998\n",
      "Finished scraping 1999\n",
      "Finished scraping 2000\n",
      "Finished scraping 2001\n",
      "Finished scraping 2002\n",
      "Finished scraping 2003\n",
      "Finished scraping 2004\n",
      "Finished scraping 2005\n",
      "Finished scraping 2006\n",
      "Finished scraping 2007\n",
      "Finished scraping 2008\n",
      "Finished scraping 2009\n",
      "Finished scraping 2010\n",
      "Finished scraping 2011\n",
      "Finished scraping 2012\n",
      "Finished scraping 2013\n",
      "Finished scraping 2014\n",
      "Finished scraping 2015\n",
      "Finished scraping 2016\n",
      "Finished scraping 2017\n",
      "Finished scraping 2018\n",
      "Finished scraping 2019\n",
      "Finished scraping 2020\n",
      "Finished scraping 2021\n",
      "Finished scraping 2022\n"
     ]
    }
   ],
   "source": [
    "sal_all = []\n",
    "\n",
    "for year in years:\n",
    "    with open('webscraping/salary/{}.html'.format(year), encoding=\"utf-8\") as file:\n",
    "        page = file.read()\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    salary_table = soup.find(class_=\"hh-salaries-ranking-table\")\n",
    "    salaries1 = pd.read_html(str(salary_table))[0].drop(columns=\"Unnamed: 0\")    \n",
    "    salaries1['Year'] = year\n",
    "    salaries1.rename(columns={salaries1.columns.tolist()[1]: 'Salary',\n",
    "                              salaries1.columns.tolist()[2]: 'Salary_Adj'}, inplace=True)\n",
    "    \n",
    "    print(f'Finished scraping {year}')\n",
    "    sal_all.append(salaries1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "942b523d-818b-43f0-9cb8-9fe4a061576a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15778, 4)\n",
      "1990-2022\n"
     ]
    }
   ],
   "source": [
    "salaries = pd.concat(sal_all)\n",
    "salaries.to_csv('../data/salaries.csv', index=False)\n",
    "print(salaries.shape)\n",
    "print(f'{salaries.Year.min()}-{salaries.Year.max()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812ee064-12d9-4586-88e2-79ac81558289",
   "metadata": {
    "tags": []
   },
   "source": [
    "## II. Team Payroll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "818c65d8-0e69-418b-b98e-75e22c253763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished writing 1990, waiting ... 5.22\n",
      "Finished writing 1991, waiting ... 5.21\n",
      "Finished writing 1992, waiting ... 4.09\n",
      "Finished writing 1993, waiting ... 4.64\n",
      "Finished writing 1994, waiting ... 4.35\n",
      "Finished writing 1995, waiting ... 4.19\n",
      "Finished writing 1996, waiting ... 5.19\n",
      "Finished writing 1997, waiting ... 4.56\n",
      "Finished writing 1998, waiting ... 4.99\n",
      "Finished writing 1999, waiting ... 5.3\n",
      "Finished writing 2000, waiting ... 4.1\n",
      "Finished writing 2001, waiting ... 4.76\n",
      "Finished writing 2002, waiting ... 4.97\n",
      "Finished writing 2003, waiting ... 5.14\n",
      "Finished writing 2004, waiting ... 4.09\n",
      "Finished writing 2005, waiting ... 5.42\n",
      "Finished writing 2006, waiting ... 5.37\n",
      "Finished writing 2007, waiting ... 4.24\n",
      "Finished writing 2008, waiting ... 5.3\n",
      "Finished writing 2009, waiting ... 5.76\n",
      "Finished writing 2010, waiting ... 4.79\n",
      "Finished writing 2011, waiting ... 4.92\n",
      "Finished writing 2012, waiting ... 4.2\n",
      "Finished writing 2013, waiting ... 5.39\n",
      "Finished writing 2014, waiting ... 5.06\n",
      "Finished writing 2015, waiting ... 4.66\n",
      "Finished writing 2016, waiting ... 5.59\n",
      "Finished writing 2017, waiting ... 5.48\n",
      "Finished writing 2018, waiting ... 5.72\n",
      "Finished writing 2019, waiting ... 5.82\n",
      "Finished writing 2020, waiting ... 4.45\n",
      "Finished writing 2021, waiting ... 5.39\n",
      "Finished writing 2022, waiting ... 5.62\n"
     ]
    }
   ],
   "source": [
    "for year in years:\n",
    "    teamsal_url = f'https://hoopshype.com/salaries/{year}-{year+1}/'\n",
    "    url = teamsal_url.format(year)\n",
    "    res = requests.get(url)\n",
    "    if res.status_code >= 200:\n",
    "        with open(\"webscraping/team/payroll/{}.html\".format(year), \"w+\", encoding=\"utf-8\") as file:\n",
    "            file.write(res.text)\n",
    "            lag = np.random.uniform(4,6)\n",
    "            print(f'Finished writing {year}, waiting ... {round(lag,2)}')\n",
    "            time.sleep(lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a9fab8dc-a51f-4ba9-9ce3-94daacd1f656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished scraping 1990\n",
      "Finished scraping 1991\n",
      "Finished scraping 1992\n",
      "Finished scraping 1993\n",
      "Finished scraping 1994\n",
      "Finished scraping 1995\n",
      "Finished scraping 1996\n",
      "Finished scraping 1997\n",
      "Finished scraping 1998\n",
      "Finished scraping 1999\n",
      "Finished scraping 2000\n",
      "Finished scraping 2001\n",
      "Finished scraping 2002\n",
      "Finished scraping 2003\n",
      "Finished scraping 2004\n",
      "Finished scraping 2005\n",
      "Finished scraping 2006\n",
      "Finished scraping 2007\n",
      "Finished scraping 2008\n",
      "Finished scraping 2009\n",
      "Finished scraping 2010\n",
      "Finished scraping 2011\n",
      "Finished scraping 2012\n",
      "Finished scraping 2013\n",
      "Finished scraping 2014\n",
      "Finished scraping 2015\n",
      "Finished scraping 2016\n",
      "Finished scraping 2017\n",
      "Finished scraping 2018\n",
      "Finished scraping 2019\n",
      "Finished scraping 2020\n",
      "Finished scraping 2021\n",
      "Finished scraping 2022\n"
     ]
    }
   ],
   "source": [
    "teamsal_all = []\n",
    "\n",
    "for year in years:\n",
    "    with open('webscraping/team/payroll/{}.html'.format(year), encoding=\"utf-8\") as file:\n",
    "        page = file.read()\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    teamsalary_table = soup.find(class_=\"hh-salaries-ranking-table\")\n",
    "    teamsalaries1 = pd.read_html(str(teamsalary_table))[0].drop(columns=\"Unnamed: 0\")    \n",
    "    teamsalaries1['Year'] = year\n",
    "    teamsalaries1.rename(columns={teamsalaries1.columns.tolist()[1]: 'Payroll',\n",
    "                              teamsalaries1.columns.tolist()[2]: 'Payroll_Adj'}, inplace=True) # Adjusted for 2022-2023 dollars\n",
    "    \n",
    "    print(f'Finished scraping {year}')\n",
    "    teamsal_all.append(teamsalaries1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd87dd84-0c1b-464d-8b7f-b9edc2dfeda7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(966, 4)\n",
      "1990-2022\n"
     ]
    }
   ],
   "source": [
    "teamsalaries = pd.concat(teamsal_all)\n",
    "teamsalaries.to_csv('../data/team_payroll.csv', index=False)\n",
    "print(teamsalaries.shape)\n",
    "print(f'{teamsalaries.Year.min()}-{teamsalaries.Year.max()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8a7d66-e2fe-4206-81b5-bdc526378a76",
   "metadata": {
    "tags": []
   },
   "source": [
    "## III. Salary Caps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fc61b76-4fec-4172-95d1-0de031991586",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "url = 'https://www.basketball-reference.com/contracts/salary-cap-history.html'\n",
    "driver.get(url)\n",
    "driver.execute_script('window.scrollTo(1,10000)')\n",
    "html = driver.page_source\n",
    "\n",
    "with open('webscraping/salary/salarycap/salarycap.html', \"w+\", encoding=\"utf-8\") as file:\n",
    "    file.write(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3fd651c-1b65-4282-afc0-7133154c8c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('webscraping/salary/salarycap/salarycap.html', encoding=\"utf-8\") as file:\n",
    "    page = file.read()\n",
    "soup = BeautifulSoup(page, 'html.parser')\n",
    "table = soup.find('table', {'id' : 'salary_cap_history'})\n",
    "salarycap = pd.read_html(str(table))[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad871adc-78c2-44b9-81ce-90a9e3eb508f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "salarycap\n",
    "salarycap.to_csv('../data/salarycap.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1246b1-7cc9-4b83-b477-4cb91803d1a1",
   "metadata": {},
   "source": [
    "## **2. Statistics Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8853b558-4b8b-48e8-b00f-2f3671aff715",
   "metadata": {
    "tags": []
   },
   "source": [
    "## IV. Player Statistics\n",
    "##### We will be scraping 3 types of player statistics: per-game, totals, and advanced stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7e0d065f-b39e-49f3-8d12-2cb28557543d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = ['per_game', 'totals', 'advanced']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "88a7f150-1083-443b-9856-1c5972abad6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished writing 1990 per_game stats, waiting ... 4.23\n",
      "Finished writing 1991 per_game stats, waiting ... 4.63\n",
      "Finished writing 1992 per_game stats, waiting ... 4.65\n",
      "Finished writing 1993 per_game stats, waiting ... 4.75\n",
      "Finished writing 1994 per_game stats, waiting ... 4.52\n",
      "Finished writing 1995 per_game stats, waiting ... 4.18\n",
      "Finished writing 1996 per_game stats, waiting ... 5.06\n",
      "Finished writing 1997 per_game stats, waiting ... 4.73\n",
      "Finished writing 1998 per_game stats, waiting ... 5.98\n",
      "Finished writing 1999 per_game stats, waiting ... 5.28\n",
      "Finished writing 2000 per_game stats, waiting ... 4.95\n",
      "Finished writing 2001 per_game stats, waiting ... 5.98\n",
      "Finished writing 2002 per_game stats, waiting ... 5.79\n",
      "Finished writing 2003 per_game stats, waiting ... 5.83\n",
      "Finished writing 2004 per_game stats, waiting ... 5.64\n",
      "Finished writing 2005 per_game stats, waiting ... 4.12\n",
      "Finished writing 2006 per_game stats, waiting ... 5.98\n",
      "Finished writing 2007 per_game stats, waiting ... 4.78\n",
      "Finished writing 2008 per_game stats, waiting ... 4.66\n",
      "Finished writing 2009 per_game stats, waiting ... 5.27\n",
      "Finished writing 2010 per_game stats, waiting ... 4.55\n",
      "Finished writing 2011 per_game stats, waiting ... 5.42\n",
      "Finished writing 2012 per_game stats, waiting ... 5.11\n",
      "Finished writing 2013 per_game stats, waiting ... 5.42\n",
      "Finished writing 2014 per_game stats, waiting ... 5.5\n",
      "Finished writing 2015 per_game stats, waiting ... 4.16\n",
      "Finished writing 2016 per_game stats, waiting ... 5.76\n",
      "Finished writing 2017 per_game stats, waiting ... 5.22\n",
      "Finished writing 2018 per_game stats, waiting ... 4.84\n",
      "Finished writing 2019 per_game stats, waiting ... 5.32\n",
      "Finished writing 2020 per_game stats, waiting ... 4.72\n",
      "Finished writing 2021 per_game stats, waiting ... 4.67\n",
      "Finished writing 2022 per_game stats, waiting ... 4.87\n",
      "Finished writing 1990 totals stats, waiting ... 5.04\n",
      "Finished writing 1991 totals stats, waiting ... 5.63\n",
      "Finished writing 1992 totals stats, waiting ... 4.56\n",
      "Finished writing 1993 totals stats, waiting ... 5.86\n",
      "Finished writing 1994 totals stats, waiting ... 4.27\n",
      "Finished writing 1995 totals stats, waiting ... 4.1\n",
      "Finished writing 1996 totals stats, waiting ... 4.95\n",
      "Finished writing 1997 totals stats, waiting ... 4.6\n",
      "Finished writing 1998 totals stats, waiting ... 5.54\n",
      "Finished writing 1999 totals stats, waiting ... 4.09\n",
      "Finished writing 2000 totals stats, waiting ... 4.69\n",
      "Finished writing 2001 totals stats, waiting ... 4.62\n",
      "Finished writing 2002 totals stats, waiting ... 5.43\n",
      "Finished writing 2003 totals stats, waiting ... 4.3\n",
      "Finished writing 2004 totals stats, waiting ... 5.57\n",
      "Finished writing 2005 totals stats, waiting ... 4.08\n",
      "Finished writing 2006 totals stats, waiting ... 5.85\n",
      "Finished writing 2007 totals stats, waiting ... 5.65\n",
      "Finished writing 2008 totals stats, waiting ... 5.75\n",
      "Finished writing 2009 totals stats, waiting ... 5.84\n",
      "Finished writing 2010 totals stats, waiting ... 4.79\n",
      "Finished writing 2011 totals stats, waiting ... 5.38\n",
      "Finished writing 2012 totals stats, waiting ... 5.46\n",
      "Finished writing 2013 totals stats, waiting ... 5.52\n",
      "Finished writing 2014 totals stats, waiting ... 5.36\n",
      "Finished writing 2015 totals stats, waiting ... 4.69\n",
      "Finished writing 2016 totals stats, waiting ... 4.46\n",
      "Finished writing 2017 totals stats, waiting ... 5.74\n",
      "Finished writing 2018 totals stats, waiting ... 5.71\n",
      "Finished writing 2019 totals stats, waiting ... 5.98\n",
      "Finished writing 2020 totals stats, waiting ... 4.18\n",
      "Finished writing 2021 totals stats, waiting ... 5.22\n",
      "Finished writing 2022 totals stats, waiting ... 4.7\n",
      "Finished writing 1990 advanced stats, waiting ... 5.89\n",
      "Finished writing 1991 advanced stats, waiting ... 4.58\n",
      "Finished writing 1992 advanced stats, waiting ... 5.6\n",
      "Finished writing 1993 advanced stats, waiting ... 4.37\n",
      "Finished writing 1994 advanced stats, waiting ... 5.06\n",
      "Finished writing 1995 advanced stats, waiting ... 4.44\n",
      "Finished writing 1996 advanced stats, waiting ... 5.0\n",
      "Finished writing 1997 advanced stats, waiting ... 4.36\n",
      "Finished writing 1998 advanced stats, waiting ... 5.86\n",
      "Finished writing 1999 advanced stats, waiting ... 5.63\n",
      "Finished writing 2000 advanced stats, waiting ... 4.96\n",
      "Finished writing 2001 advanced stats, waiting ... 5.01\n",
      "Finished writing 2002 advanced stats, waiting ... 5.38\n",
      "Finished writing 2003 advanced stats, waiting ... 4.24\n",
      "Finished writing 2004 advanced stats, waiting ... 5.37\n",
      "Finished writing 2005 advanced stats, waiting ... 5.88\n",
      "Finished writing 2006 advanced stats, waiting ... 4.68\n",
      "Finished writing 2007 advanced stats, waiting ... 4.73\n",
      "Finished writing 2008 advanced stats, waiting ... 4.51\n",
      "Finished writing 2009 advanced stats, waiting ... 4.61\n",
      "Finished writing 2010 advanced stats, waiting ... 4.76\n",
      "Finished writing 2011 advanced stats, waiting ... 5.91\n",
      "Finished writing 2012 advanced stats, waiting ... 5.11\n",
      "Finished writing 2013 advanced stats, waiting ... 4.89\n",
      "Finished writing 2014 advanced stats, waiting ... 5.2\n",
      "Finished writing 2015 advanced stats, waiting ... 5.36\n",
      "Finished writing 2016 advanced stats, waiting ... 4.38\n",
      "Finished writing 2017 advanced stats, waiting ... 4.85\n",
      "Finished writing 2018 advanced stats, waiting ... 5.7\n",
      "Finished writing 2019 advanced stats, waiting ... 4.09\n",
      "Finished writing 2020 advanced stats, waiting ... 4.26\n",
      "Finished writing 2021 advanced stats, waiting ... 5.14\n",
      "Finished writing 2022 advanced stats, waiting ... 4.43\n"
     ]
    }
   ],
   "source": [
    "for stat in stats:\n",
    "    for year in years:\n",
    "        url = f'https://www.basketball-reference.com/leagues/NBA_{year+1}_{stat}.html' # +1 here because site is determining year by the season end date and our list is defining it by season start\n",
    "        driver.get(url)\n",
    "        driver.execute_script('window.scrollTo(1,10000)')\n",
    "        html = driver.page_source\n",
    "\n",
    "        with open(f'webscraping/players/{stat}/{year}.html', \"w+\", encoding=\"utf-8\") as file:\n",
    "            file.write(html)\n",
    "        lag = np.random.uniform(4,6)\n",
    "        print(f'Finished writing {year} {stat} stats, waiting ... {round(lag,2)}')\n",
    "        time.sleep(lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "92858e68-3b81-4fe8-aaec-fe749fcf45f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished scraping 1990 per_game stats\n",
      "Finished scraping 1991 per_game stats\n",
      "Finished scraping 1992 per_game stats\n",
      "Finished scraping 1993 per_game stats\n",
      "Finished scraping 1994 per_game stats\n",
      "Finished scraping 1995 per_game stats\n",
      "Finished scraping 1996 per_game stats\n",
      "Finished scraping 1997 per_game stats\n",
      "Finished scraping 1998 per_game stats\n",
      "Finished scraping 1999 per_game stats\n",
      "Finished scraping 2000 per_game stats\n",
      "Finished scraping 2001 per_game stats\n",
      "Finished scraping 2002 per_game stats\n",
      "Finished scraping 2003 per_game stats\n",
      "Finished scraping 2004 per_game stats\n",
      "Finished scraping 2005 per_game stats\n",
      "Finished scraping 2006 per_game stats\n",
      "Finished scraping 2007 per_game stats\n",
      "Finished scraping 2008 per_game stats\n",
      "Finished scraping 2009 per_game stats\n",
      "Finished scraping 2010 per_game stats\n",
      "Finished scraping 2011 per_game stats\n",
      "Finished scraping 2012 per_game stats\n",
      "Finished scraping 2013 per_game stats\n",
      "Finished scraping 2014 per_game stats\n",
      "Finished scraping 2015 per_game stats\n",
      "Finished scraping 2016 per_game stats\n",
      "Finished scraping 2017 per_game stats\n",
      "Finished scraping 2018 per_game stats\n",
      "Finished scraping 2019 per_game stats\n",
      "Finished scraping 2020 per_game stats\n",
      "Finished scraping 2021 per_game stats\n",
      "Finished scraping 2022 per_game stats\n",
      "Finished scraping 1990 totals stats\n",
      "Finished scraping 1991 totals stats\n",
      "Finished scraping 1992 totals stats\n",
      "Finished scraping 1993 totals stats\n",
      "Finished scraping 1994 totals stats\n",
      "Finished scraping 1995 totals stats\n",
      "Finished scraping 1996 totals stats\n",
      "Finished scraping 1997 totals stats\n",
      "Finished scraping 1998 totals stats\n",
      "Finished scraping 1999 totals stats\n",
      "Finished scraping 2000 totals stats\n",
      "Finished scraping 2001 totals stats\n",
      "Finished scraping 2002 totals stats\n",
      "Finished scraping 2003 totals stats\n",
      "Finished scraping 2004 totals stats\n",
      "Finished scraping 2005 totals stats\n",
      "Finished scraping 2006 totals stats\n",
      "Finished scraping 2007 totals stats\n",
      "Finished scraping 2008 totals stats\n",
      "Finished scraping 2009 totals stats\n",
      "Finished scraping 2010 totals stats\n",
      "Finished scraping 2011 totals stats\n",
      "Finished scraping 2012 totals stats\n",
      "Finished scraping 2013 totals stats\n",
      "Finished scraping 2014 totals stats\n",
      "Finished scraping 2015 totals stats\n",
      "Finished scraping 2016 totals stats\n",
      "Finished scraping 2017 totals stats\n",
      "Finished scraping 2018 totals stats\n",
      "Finished scraping 2019 totals stats\n",
      "Finished scraping 2020 totals stats\n",
      "Finished scraping 2021 totals stats\n",
      "Finished scraping 2022 totals stats\n",
      "Finished scraping 1990 advanced stats\n",
      "Finished scraping 1991 advanced stats\n",
      "Finished scraping 1992 advanced stats\n",
      "Finished scraping 1993 advanced stats\n",
      "Finished scraping 1994 advanced stats\n",
      "Finished scraping 1995 advanced stats\n",
      "Finished scraping 1996 advanced stats\n",
      "Finished scraping 1997 advanced stats\n",
      "Finished scraping 1998 advanced stats\n",
      "Finished scraping 1999 advanced stats\n",
      "Finished scraping 2000 advanced stats\n",
      "Finished scraping 2001 advanced stats\n",
      "Finished scraping 2002 advanced stats\n",
      "Finished scraping 2003 advanced stats\n",
      "Finished scraping 2004 advanced stats\n",
      "Finished scraping 2005 advanced stats\n",
      "Finished scraping 2006 advanced stats\n",
      "Finished scraping 2007 advanced stats\n",
      "Finished scraping 2008 advanced stats\n",
      "Finished scraping 2009 advanced stats\n",
      "Finished scraping 2010 advanced stats\n",
      "Finished scraping 2011 advanced stats\n",
      "Finished scraping 2012 advanced stats\n",
      "Finished scraping 2013 advanced stats\n",
      "Finished scraping 2014 advanced stats\n",
      "Finished scraping 2015 advanced stats\n",
      "Finished scraping 2016 advanced stats\n",
      "Finished scraping 2017 advanced stats\n",
      "Finished scraping 2018 advanced stats\n",
      "Finished scraping 2019 advanced stats\n",
      "Finished scraping 2020 advanced stats\n",
      "Finished scraping 2021 advanced stats\n",
      "Finished scraping 2022 advanced stats\n"
     ]
    }
   ],
   "source": [
    "pg_all = []\n",
    "tot_all = []\n",
    "adv_all = []\n",
    "\n",
    "for stat in stats:\n",
    "    for year in years:  \n",
    "        with open(f'webscraping/players/{stat}/{year}.html', encoding=\"utf-8\") as file:\n",
    "            page = file.read()\n",
    "        soup = BeautifulSoup(page, 'html.parser')\n",
    "        table = soup.find('table', {'id' : f'{stat}_stats'})\n",
    "        soup.find('tr', class_ = 'thead').decompose()\n",
    "        df = pd.read_html(str(table))[0] \n",
    "        df['Year'] = year\n",
    "        df['Stat'] = stat\n",
    "        \n",
    "        print(f'Finished scraping {year} {stat} stats')\n",
    "        \n",
    "        if stat == 'per_game':\n",
    "            pg_all.append(df)\n",
    "        if stat == 'totals':\n",
    "            tot_all.append(df)\n",
    "        if stat == 'advanced':\n",
    "            adv_all.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02cc0b93-2ff7-42fc-b929-8dbc3c0c9747",
   "metadata": {},
   "outputs": [],
   "source": [
    "b0 ='\\033[1m'\n",
    "b1 = '\\033[0;0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34161333-32cd-4e70-9a04-28f43bab485d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pg_all' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pg \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(\u001b[43mpg_all\u001b[49m)\n\u001b[0;32m      2\u001b[0m pg\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/per_game_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m --- <b>Per Game</b> ---\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pg_all' is not defined"
     ]
    }
   ],
   "source": [
    "pg = pd.concat(pg_all)\n",
    "pg.to_csv('../data/per_game_data.csv', index=False)\n",
    "print(f' --- {b0}Per Game{b1} ---')\n",
    "print(pg.shape)\n",
    "print(f'{pg.Year.min()}-{pg.Year.max()}')\n",
    "\n",
    "tot = pd.concat(tot_all)\n",
    "tot.to_csv('../data/totals_data.csv', index=False)\n",
    "print(f'\\n --- {b0}Totals{b1} ---')\n",
    "print(tot.shape)\n",
    "print(f'{tot.Year.min()}-{tot.Year.max()}')\n",
    "\n",
    "adv = pd.concat(adv_all)\n",
    "adv.to_csv('../data/advanced_data.csv', index=False)\n",
    "print(f'\\n --- {b0}Advanced{b1} ---')\n",
    "print(adv.shape)\n",
    "print(f'{adv.Year.min()}-{adv.Year.max()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7178867c-5d9e-4e89-aee7-388747c4add2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rk</th>\n",
       "      <th>Player</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tm</th>\n",
       "      <th>G</th>\n",
       "      <th>GS</th>\n",
       "      <th>MP</th>\n",
       "      <th>FG</th>\n",
       "      <th>FGA</th>\n",
       "      <th>...</th>\n",
       "      <th>DRB</th>\n",
       "      <th>TRB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PF</th>\n",
       "      <th>PTS</th>\n",
       "      <th>Year</th>\n",
       "      <th>Stat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Mark Acres</td>\n",
       "      <td>C</td>\n",
       "      <td>27</td>\n",
       "      <td>ORL</td>\n",
       "      <td>80</td>\n",
       "      <td>50</td>\n",
       "      <td>21.1</td>\n",
       "      <td>1.7</td>\n",
       "      <td>3.6</td>\n",
       "      <td>...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1990</td>\n",
       "      <td>per_game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Michael Adams</td>\n",
       "      <td>PG</td>\n",
       "      <td>27</td>\n",
       "      <td>DEN</td>\n",
       "      <td>79</td>\n",
       "      <td>74</td>\n",
       "      <td>34.1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>...</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>15.5</td>\n",
       "      <td>1990</td>\n",
       "      <td>per_game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Mark Aguirre</td>\n",
       "      <td>SF</td>\n",
       "      <td>30</td>\n",
       "      <td>DET</td>\n",
       "      <td>78</td>\n",
       "      <td>40</td>\n",
       "      <td>25.7</td>\n",
       "      <td>5.6</td>\n",
       "      <td>11.5</td>\n",
       "      <td>...</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.6</td>\n",
       "      <td>14.1</td>\n",
       "      <td>1990</td>\n",
       "      <td>per_game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Danny Ainge</td>\n",
       "      <td>PG</td>\n",
       "      <td>30</td>\n",
       "      <td>SAC</td>\n",
       "      <td>75</td>\n",
       "      <td>68</td>\n",
       "      <td>36.4</td>\n",
       "      <td>6.7</td>\n",
       "      <td>15.4</td>\n",
       "      <td>...</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>17.9</td>\n",
       "      <td>1990</td>\n",
       "      <td>per_game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Mark Alarie</td>\n",
       "      <td>PF</td>\n",
       "      <td>26</td>\n",
       "      <td>WSB</td>\n",
       "      <td>82</td>\n",
       "      <td>10</td>\n",
       "      <td>23.1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.6</td>\n",
       "      <td>...</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.7</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1990</td>\n",
       "      <td>per_game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>601</td>\n",
       "      <td>Thaddeus Young</td>\n",
       "      <td>PF</td>\n",
       "      <td>33</td>\n",
       "      <td>TOR</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>18.3</td>\n",
       "      <td>2.6</td>\n",
       "      <td>5.5</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2022</td>\n",
       "      <td>per_game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>602</td>\n",
       "      <td>Trae Young</td>\n",
       "      <td>PG</td>\n",
       "      <td>23</td>\n",
       "      <td>ATL</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>34.9</td>\n",
       "      <td>9.4</td>\n",
       "      <td>20.3</td>\n",
       "      <td>...</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>9.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>28.4</td>\n",
       "      <td>2022</td>\n",
       "      <td>per_game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>603</td>\n",
       "      <td>Omer Yurtseven</td>\n",
       "      <td>C</td>\n",
       "      <td>23</td>\n",
       "      <td>MIA</td>\n",
       "      <td>56</td>\n",
       "      <td>12</td>\n",
       "      <td>12.6</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.4</td>\n",
       "      <td>...</td>\n",
       "      <td>3.7</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2022</td>\n",
       "      <td>per_game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>604</td>\n",
       "      <td>Cody Zeller</td>\n",
       "      <td>C</td>\n",
       "      <td>29</td>\n",
       "      <td>POR</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>3.3</td>\n",
       "      <td>...</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2022</td>\n",
       "      <td>per_game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>605</td>\n",
       "      <td>Ivica Zubac</td>\n",
       "      <td>C</td>\n",
       "      <td>24</td>\n",
       "      <td>LAC</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>24.4</td>\n",
       "      <td>4.1</td>\n",
       "      <td>6.5</td>\n",
       "      <td>...</td>\n",
       "      <td>5.6</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.7</td>\n",
       "      <td>10.3</td>\n",
       "      <td>2022</td>\n",
       "      <td>per_game</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19362 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Rk          Player Pos Age   Tm   G  GS    MP   FG   FGA  ...  DRB  TRB  \\\n",
       "0      1      Mark Acres   C  27  ORL  80  50  21.1  1.7   3.6  ...  3.5  5.4   \n",
       "1      2   Michael Adams  PG  27  DEN  79  74  34.1  5.0  12.5  ...  2.2  2.8   \n",
       "2      3    Mark Aguirre  SF  30  DET  78  40  25.7  5.6  11.5  ...  2.4  3.9   \n",
       "3      4     Danny Ainge  PG  30  SAC  75  68  36.4  6.7  15.4  ...  3.4  4.3   \n",
       "4      5     Mark Alarie  PF  26  WSB  82  10  23.1  4.5   9.6  ...  2.7  4.6   \n",
       "..   ...             ...  ..  ..  ...  ..  ..   ...  ...   ...  ...  ...  ...   \n",
       "836  601  Thaddeus Young  PF  33  TOR  26   0  18.3  2.6   5.5  ...  2.9  4.4   \n",
       "837  602      Trae Young  PG  23  ATL  76  76  34.9  9.4  20.3  ...  3.1  3.7   \n",
       "838  603  Omer Yurtseven   C  23  MIA  56  12  12.6  2.3   4.4  ...  3.7  5.3   \n",
       "839  604     Cody Zeller   C  29  POR  27   0  13.1  1.9   3.3  ...  2.8  4.6   \n",
       "840  605     Ivica Zubac   C  24  LAC  76  76  24.4  4.1   6.5  ...  5.6  8.5   \n",
       "\n",
       "     AST  STL  BLK  TOV   PF   PTS  Year      Stat  \n",
       "0    0.8  0.5  0.3  0.9  3.1   4.5  1990  per_game  \n",
       "1    6.3  1.5  0.0  1.8  1.7  15.5  1990  per_game  \n",
       "2    1.9  0.4  0.2  1.6  2.6  14.1  1990  per_game  \n",
       "3    6.0  1.5  0.2  2.5  3.2  17.9  1990  per_game  \n",
       "4    1.7  0.7  0.5  1.2  2.7  10.5  1990  per_game  \n",
       "..   ...  ...  ...  ...  ...   ...   ...       ...  \n",
       "836  1.7  1.2  0.4  0.8  1.7   6.3  2022  per_game  \n",
       "837  9.7  0.9  0.1  4.0  1.7  28.4  2022  per_game  \n",
       "838  0.9  0.3  0.4  0.7  1.5   5.3  2022  per_game  \n",
       "839  0.8  0.3  0.2  0.7  2.1   5.2  2022  per_game  \n",
       "840  1.6  0.5  1.0  1.5  2.7  10.3  2022  per_game  \n",
       "\n",
       "[19362 rows x 32 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PREVIEW TABLES\n",
    "pg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497ab64d-7192-437d-b978-8cc89aee516b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccd78db-e393-4035-a5e4-d67f4c7d039d",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1746dabb-1c28-47fb-83c6-8a997cd6f2f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## V. All-NBA Team Winners and Nominees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "aef1cb5a-17c7-4fc9-97f6-a2efbba67826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished writing 1990, waiting ... 4.2\n",
      "Finished writing 1991, waiting ... 4.77\n",
      "Finished writing 1992, waiting ... 5.02\n",
      "Finished writing 1993, waiting ... 4.91\n",
      "Finished writing 1994, waiting ... 4.19\n",
      "Finished writing 1995, waiting ... 4.94\n",
      "Finished writing 1996, waiting ... 5.23\n",
      "Finished writing 1997, waiting ... 4.07\n",
      "Finished writing 1998, waiting ... 5.5\n",
      "Finished writing 1999, waiting ... 5.91\n",
      "Finished writing 2000, waiting ... 5.72\n",
      "Finished writing 2001, waiting ... 4.69\n",
      "Finished writing 2002, waiting ... 4.91\n",
      "Finished writing 2003, waiting ... 5.77\n",
      "Finished writing 2004, waiting ... 4.43\n",
      "Finished writing 2005, waiting ... 5.03\n",
      "Finished writing 2006, waiting ... 5.52\n",
      "Finished writing 2007, waiting ... 5.45\n",
      "Finished writing 2008, waiting ... 5.37\n",
      "Finished writing 2009, waiting ... 4.78\n",
      "Finished writing 2010, waiting ... 5.88\n",
      "Finished writing 2011, waiting ... 5.33\n",
      "Finished writing 2012, waiting ... 4.96\n",
      "Finished writing 2013, waiting ... 4.12\n",
      "Finished writing 2014, waiting ... 4.51\n",
      "Finished writing 2015, waiting ... 5.04\n",
      "Finished writing 2016, waiting ... 4.68\n",
      "Finished writing 2017, waiting ... 4.77\n",
      "Finished writing 2018, waiting ... 4.35\n",
      "Finished writing 2019, waiting ... 4.42\n",
      "Finished writing 2020, waiting ... 4.18\n",
      "Finished writing 2021, waiting ... 5.4\n",
      "Finished writing 2022, waiting ... 5.96\n"
     ]
    }
   ],
   "source": [
    "for year in years:\n",
    "    url = f'https://www.basketball-reference.com/awards/awards_{year+1}.html'\n",
    "    driver.get(url)\n",
    "    driver.execute_script('window.scrollTo(1,10000)') # Assures entire page is saved for scraping\n",
    "    html = driver.page_source\n",
    "\n",
    "    with open(f'webscraping/players/all_team/{year}.html', \"w+\", encoding=\"utf-8\") as file:\n",
    "        file.write(html)\n",
    "    lag = np.random.uniform(4,6)\n",
    "    print(f'Finished writing {year}, waiting ... {round(lag,2)}')\n",
    "    time.sleep(lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a80b27c6-ea7b-4992-8d23-73b71f854ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished scraping 1990\n",
      "Finished scraping 1991\n",
      "Finished scraping 1992\n",
      "Finished scraping 1993\n",
      "Finished scraping 1994\n",
      "Finished scraping 1995\n",
      "Finished scraping 1996\n",
      "Finished scraping 1997\n",
      "Finished scraping 1998\n",
      "Finished scraping 1999\n",
      "Finished scraping 2000\n",
      "Finished scraping 2001\n",
      "Finished scraping 2002\n",
      "Finished scraping 2003\n",
      "Finished scraping 2004\n",
      "Finished scraping 2005\n",
      "Finished scraping 2006\n",
      "Finished scraping 2007\n",
      "Finished scraping 2008\n",
      "Finished scraping 2009\n",
      "Finished scraping 2010\n",
      "Finished scraping 2011\n",
      "Finished scraping 2012\n",
      "Finished scraping 2013\n",
      "Finished scraping 2014\n",
      "Finished scraping 2015\n",
      "Finished scraping 2016\n",
      "Finished scraping 2017\n",
      "Finished scraping 2018\n",
      "Finished scraping 2019\n",
      "Finished scraping 2020\n",
      "Finished scraping 2021\n",
      "Finished scraping 2022\n"
     ]
    }
   ],
   "source": [
    "all = []\n",
    "\n",
    "for year in years:  \n",
    "    with open(f'webscraping/players/all_team/{year}.html', encoding=\"utf-8\") as file:\n",
    "        page = file.read()\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    table = soup.find('table', {'id' : 'leading_all_nba'})\n",
    "    try:\n",
    "        soup.find('tr', class_ = 'over_header').decompose()\n",
    "        soup.find('tr', {'id' : 'start_2nd'}).decompose()\n",
    "        soup.find('tr', {'id' : 'start_3rd'}).decompose()\n",
    "        soup.find('tr', {'id' : 'start_ORV'}).decompose()\n",
    "        soup.find('div', class_ = 'topscroll_div').decompose()\n",
    "    except:\n",
    "        soup.find('tr', class_ = 'over_header').decompose()\n",
    "        soup.find('tr', {'id' : 'start_1T'}).decompose()\n",
    "        soup.find('tr', {'id' : 'start_2T'}).decompose()\n",
    "        soup.find('tr', {'id' : 'start_3T'}).decompose()\n",
    "        soup.find('tr', {'id' : 'start_ORV'}).decompose()\n",
    "        soup.find('div', class_ = 'topscroll_div').decompose()\n",
    "               \n",
    "    df = pd.read_html(str(table), header=1)[0] \n",
    "    df['Year'] = year   \n",
    "    \n",
    "    print(f'Finished scraping {year}')\n",
    "    all.append(df)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1cc812ce-f9d2-45b4-8ea3-35d3ae6476a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1354, 24)\n",
      "1990-2022\n"
     ]
    }
   ],
   "source": [
    "all_nba = pd.concat(all)\n",
    "all_nba.to_csv('../data/all_nba_teams.csv', index=False)\n",
    "print(all_nba.shape)\n",
    "print(f'{all_nba.Year.min()}-{all_nba.Year.max()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450bba19-b943-4f7c-a09a-b2e4b236bd9a",
   "metadata": {},
   "source": [
    "## **3. Additional Performance-Related Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20defc98-6827-4a0b-9bff-a1db47333da8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## VI. Team Rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9619057d-c323-4fe6-b9ca-ebeb573387d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished writing 1990, waiting ... 5.45\n",
      "Finished writing 1991, waiting ... 5.1\n",
      "Finished writing 1992, waiting ... 4.57\n",
      "Finished writing 1993, waiting ... 5.03\n",
      "Finished writing 1994, waiting ... 5.69\n",
      "Finished writing 1995, waiting ... 5.31\n",
      "Finished writing 1996, waiting ... 4.55\n",
      "Finished writing 1997, waiting ... 5.23\n",
      "Finished writing 1998, waiting ... 5.28\n",
      "Finished writing 1999, waiting ... 4.49\n",
      "Finished writing 2000, waiting ... 5.5\n",
      "Finished writing 2001, waiting ... 5.35\n",
      "Finished writing 2002, waiting ... 4.46\n",
      "Finished writing 2003, waiting ... 5.55\n",
      "Finished writing 2004, waiting ... 4.44\n",
      "Finished writing 2005, waiting ... 4.35\n",
      "Finished writing 2006, waiting ... 4.54\n",
      "Finished writing 2007, waiting ... 4.95\n",
      "Finished writing 2008, waiting ... 4.22\n",
      "Finished writing 2009, waiting ... 4.37\n",
      "Finished writing 2010, waiting ... 4.24\n",
      "Finished writing 2011, waiting ... 4.1\n",
      "Finished writing 2012, waiting ... 4.65\n",
      "Finished writing 2013, waiting ... 4.54\n",
      "Finished writing 2014, waiting ... 4.73\n",
      "Finished writing 2015, waiting ... 4.28\n",
      "Finished writing 2016, waiting ... 5.13\n",
      "Finished writing 2017, waiting ... 5.9\n",
      "Finished writing 2018, waiting ... 4.63\n",
      "Finished writing 2019, waiting ... 5.88\n",
      "Finished writing 2020, waiting ... 5.58\n",
      "Finished writing 2021, waiting ... 5.18\n",
      "Finished writing 2022, waiting ... 4.78\n"
     ]
    }
   ],
   "source": [
    "for year in years:\n",
    "    url = f'https://www.basketball-reference.com/leagues/NBA_{year+1}_ratings.html' # +1 here because site is determining year by the season end date and our list is defining it by season start\n",
    "    res = requests.get(url)\n",
    "    if res.status_code >= 200:\n",
    "        with open(\"webscraping/team/rank/{}.html\".format(year), \"w+\", encoding=\"utf-8\") as file:\n",
    "            file.write(res.text)\n",
    "            lag = np.random.uniform(4,6)\n",
    "            print(f'Finished writing {year}, waiting ... {round(lag,2)}')\n",
    "            time.sleep(lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07fccdb-394c-44ca-9176-c41f42aa9928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished scraping 1990\n",
      "Finished scraping 1991\n",
      "Finished scraping 1992\n",
      "Finished scraping 1993\n",
      "Finished scraping 1994\n",
      "Finished scraping 1995\n",
      "Finished scraping 1996\n",
      "Finished scraping 1997\n",
      "Finished scraping 1998\n",
      "Finished scraping 1999\n",
      "Finished scraping 2000\n",
      "Finished scraping 2001\n",
      "Finished scraping 2002\n",
      "Finished scraping 2003\n",
      "Finished scraping 2004\n",
      "Finished scraping 2005\n",
      "Finished scraping 2006\n",
      "Finished scraping 2007\n",
      "Finished scraping 2008\n",
      "Finished scraping 2009\n",
      "Finished scraping 2010\n",
      "Finished scraping 2011\n",
      "Finished scraping 2012\n",
      "Finished scraping 2013\n",
      "Finished scraping 2014\n",
      "Finished scraping 2015\n",
      "Finished scraping 2016\n",
      "Finished scraping 2017\n",
      "Finished scraping 2018\n",
      "Finished scraping 2019\n",
      "Finished scraping 2020\n",
      "Finished scraping 2021\n",
      "Finished scraping 2022\n"
     ]
    }
   ],
   "source": [
    "all = []\n",
    "\n",
    "for year in years:\n",
    "    with open('webscraping/team/rank/{}.html'.format(year), encoding=\"utf-8\") as file:\n",
    "        page = file.read()\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    table = soup.find('table',  {'id' : 'ratings'})\n",
    "    soup.find('tr', class_ = 'over_header').decompose()\n",
    "    df = pd.read_html(str(table))[0]  \n",
    "    df['Year'] = year\n",
    "    \n",
    "    print(f'Finished scraping {year}')\n",
    "    all.append(df)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1290cb-c705-49d0-a2f5-bade44640c29",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(963, 16)\n",
      "1990-2022\n"
     ]
    }
   ],
   "source": [
    "team_rank = pd.concat(all)\n",
    "team_rank.to_csv('../data/team_rank.csv', index=False)\n",
    "print(team_rank.shape)\n",
    "print(f'{team_rank.Year.min()}-{team_rank.Year.max()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630708b3-30c7-4564-812c-818cc35e3400",
   "metadata": {
    "tags": []
   },
   "source": [
    "## VII. All-Star Appearance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ff2726-0654-4618-b193-405eb4a7195e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/List_of_NBA_All-Stars'\n",
    "res = requests.get(url)\n",
    "if res.status_code >= 200:\n",
    "    soup = BeautifulSoup(res.content, 'lxml')\n",
    "    table = soup.find('table', class_=\"wikitable sortable\")\n",
    "    \n",
    "    as_appearance = pd.read_html(str(table))[0]\n",
    "\n",
    "as_appearance.to_csv('../data/all_star_appearances.csv', index=False)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
