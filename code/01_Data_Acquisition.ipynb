{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "25301130-eea5-45a6-b2d6-283675cbdeee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-4.10.0-py3-none-any.whl (6.7 MB)\n",
      "     ---------------------------------------- 6.7/6.7 MB 8.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\farah\\anaconda3\\lib\\site-packages (from selenium) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\farah\\anaconda3\\lib\\site-packages (from selenium) (2023.5.7)\n",
      "Collecting trio~=0.17\n",
      "  Downloading trio-0.22.2-py3-none-any.whl (400 kB)\n",
      "     ------------------------------------- 400.2/400.2 kB 12.2 MB/s eta 0:00:00\n",
      "Collecting trio-websocket~=0.9\n",
      "  Downloading trio_websocket-0.10.3-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\farah\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\farah\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Collecting exceptiongroup>=1.0.0rc9\n",
      "  Downloading exceptiongroup-1.1.2-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\farah\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\farah\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: sniffio in c:\\users\\farah\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Collecting outcome\n",
      "  Downloading outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting wsproto>=0.14\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\farah\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\farah\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Collecting h11<1,>=0.9.0\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "     ---------------------------------------- 58.3/58.3 kB 3.0 MB/s eta 0:00:00\n",
      "Installing collected packages: outcome, h11, exceptiongroup, wsproto, trio, trio-websocket, selenium\n",
      "Successfully installed exceptiongroup-1.1.2 h11-0.14.0 outcome-1.2.0 selenium-4.10.0 trio-0.22.2 trio-websocket-0.10.3 wsproto-1.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8e8a98-c177-4b87-bfc3-819430657e55",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b1741b-d02d-4e69-9f10-ea536ed9ba12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import Select\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "55c557d9-c645-4103-aef2-557344c680a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3028c4a8-a856-4b06-a126-f108cdf2c491",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = list(range(1990,2023)) # stopping at 2022 which will be the 2022-23 season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4767c9c1-31eb-4d20-a79d-9998f46e2f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished writing 1990, waiting ... 5.83\n",
      "Finished writing 1991, waiting ... 4.62\n",
      "Finished writing 1992, waiting ... 4.06\n",
      "Finished writing 1993, waiting ... 4.44\n",
      "Finished writing 1994, waiting ... 5.88\n",
      "Finished writing 1995, waiting ... 5.49\n",
      "Finished writing 1996, waiting ... 5.65\n",
      "Finished writing 1997, waiting ... 4.89\n",
      "Finished writing 1998, waiting ... 5.32\n",
      "Finished writing 1999, waiting ... 5.05\n",
      "Finished writing 2000, waiting ... 4.71\n",
      "Finished writing 2001, waiting ... 4.59\n",
      "Finished writing 2002, waiting ... 4.67\n",
      "Finished writing 2003, waiting ... 5.13\n",
      "Finished writing 2004, waiting ... 5.83\n",
      "Finished writing 2005, waiting ... 4.45\n",
      "Finished writing 2006, waiting ... 5.16\n",
      "Finished writing 2007, waiting ... 4.99\n",
      "Finished writing 2008, waiting ... 4.06\n",
      "Finished writing 2009, waiting ... 4.93\n",
      "Finished writing 2010, waiting ... 5.68\n",
      "Finished writing 2011, waiting ... 4.07\n",
      "Finished writing 2012, waiting ... 5.81\n",
      "Finished writing 2013, waiting ... 5.18\n",
      "Finished writing 2014, waiting ... 4.18\n",
      "Finished writing 2015, waiting ... 4.73\n",
      "Finished writing 2016, waiting ... 4.07\n",
      "Finished writing 2017, waiting ... 4.82\n",
      "Finished writing 2018, waiting ... 4.1\n",
      "Finished writing 2019, waiting ... 5.26\n",
      "Finished writing 2020, waiting ... 4.43\n",
      "Finished writing 2021, waiting ... 4.29\n",
      "Finished writing 2022, waiting ... 5.0\n"
     ]
    }
   ],
   "source": [
    "for year in years:\n",
    "    sal_url = f'https://hoopshype.com/salaries/players/{year}-{year+1}/'\n",
    "    url = sal_url.format(year)\n",
    "    res = requests.get(url)\n",
    "    if res.status_code >= 200:\n",
    "        with open(\"webscraping/salary/{}.html\".format(year), \"w+\", encoding=\"utf-8\") as file:\n",
    "            file.write(res.text)\n",
    "            lag = np.random.uniform(4,6)\n",
    "            print(f'Finished writing {year}, waiting ... {round(lag,2)}')\n",
    "            time.sleep(lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f3744e5-28ec-40aa-b47e-04139ee1588c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished scraping 1990\n",
      "Finished scraping 1991\n",
      "Finished scraping 1992\n",
      "Finished scraping 1993\n",
      "Finished scraping 1994\n",
      "Finished scraping 1995\n",
      "Finished scraping 1996\n",
      "Finished scraping 1997\n",
      "Finished scraping 1998\n",
      "Finished scraping 1999\n",
      "Finished scraping 2000\n",
      "Finished scraping 2001\n",
      "Finished scraping 2002\n",
      "Finished scraping 2003\n",
      "Finished scraping 2004\n",
      "Finished scraping 2005\n",
      "Finished scraping 2006\n",
      "Finished scraping 2007\n",
      "Finished scraping 2008\n",
      "Finished scraping 2009\n",
      "Finished scraping 2010\n",
      "Finished scraping 2011\n",
      "Finished scraping 2012\n",
      "Finished scraping 2013\n",
      "Finished scraping 2014\n",
      "Finished scraping 2015\n",
      "Finished scraping 2016\n",
      "Finished scraping 2017\n",
      "Finished scraping 2018\n",
      "Finished scraping 2019\n",
      "Finished scraping 2020\n",
      "Finished scraping 2021\n",
      "Finished scraping 2022\n"
     ]
    }
   ],
   "source": [
    "sal_all = []\n",
    "\n",
    "for year in years:\n",
    "    with open('webscraping/salary/{}.html'.format(year), encoding=\"utf-8\") as file:\n",
    "        page = file.read()\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    salary_table = soup.find(class_=\"hh-salaries-ranking-table\")\n",
    "    salaries1 = pd.read_html(str(salary_table))[0].drop(columns=\"Unnamed: 0\")    \n",
    "    salaries1['Year'] = year\n",
    "    salaries1.rename(columns={salaries1.columns.tolist()[1]: 'Salary',\n",
    "                              salaries1.columns.tolist()[2]: 'Salary_Adj'}, inplace=True)\n",
    "    \n",
    "    print(f'Finished scraping {year}')\n",
    "    sal_all.append(salaries1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "942b523d-818b-43f0-9cb8-9fe4a061576a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15778, 4)\n",
      "1990-2022\n"
     ]
    }
   ],
   "source": [
    "salaries = pd.concat(sal_all)\n",
    "salaries.to_csv('../data/salaries.csv', index=False)\n",
    "print(salaries.shape)\n",
    "print(f'{salaries.Year.min()}-{salaries.Year.max()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33255d7-994d-4a48-bddc-02c43350079a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07efc141-141d-479d-b06e-3ee669884a43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "818c65d8-0e69-418b-b98e-75e22c253763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished writing 1990, waiting ... 5.22\n",
      "Finished writing 1991, waiting ... 5.21\n",
      "Finished writing 1992, waiting ... 4.09\n",
      "Finished writing 1993, waiting ... 4.64\n",
      "Finished writing 1994, waiting ... 4.35\n",
      "Finished writing 1995, waiting ... 4.19\n",
      "Finished writing 1996, waiting ... 5.19\n",
      "Finished writing 1997, waiting ... 4.56\n",
      "Finished writing 1998, waiting ... 4.99\n",
      "Finished writing 1999, waiting ... 5.3\n",
      "Finished writing 2000, waiting ... 4.1\n",
      "Finished writing 2001, waiting ... 4.76\n",
      "Finished writing 2002, waiting ... 4.97\n",
      "Finished writing 2003, waiting ... 5.14\n",
      "Finished writing 2004, waiting ... 4.09\n",
      "Finished writing 2005, waiting ... 5.42\n",
      "Finished writing 2006, waiting ... 5.37\n",
      "Finished writing 2007, waiting ... 4.24\n",
      "Finished writing 2008, waiting ... 5.3\n",
      "Finished writing 2009, waiting ... 5.76\n",
      "Finished writing 2010, waiting ... 4.79\n",
      "Finished writing 2011, waiting ... 4.92\n",
      "Finished writing 2012, waiting ... 4.2\n",
      "Finished writing 2013, waiting ... 5.39\n",
      "Finished writing 2014, waiting ... 5.06\n",
      "Finished writing 2015, waiting ... 4.66\n",
      "Finished writing 2016, waiting ... 5.59\n",
      "Finished writing 2017, waiting ... 5.48\n",
      "Finished writing 2018, waiting ... 5.72\n",
      "Finished writing 2019, waiting ... 5.82\n",
      "Finished writing 2020, waiting ... 4.45\n",
      "Finished writing 2021, waiting ... 5.39\n",
      "Finished writing 2022, waiting ... 5.62\n"
     ]
    }
   ],
   "source": [
    "for year in years:\n",
    "    teamsal_url = f'https://hoopshype.com/salaries/{year}-{year+1}/'\n",
    "    url = teamsal_url.format(year)\n",
    "    res = requests.get(url)\n",
    "    if res.status_code >= 200:\n",
    "        with open(\"webscraping/team/payroll/{}.html\".format(year), \"w+\", encoding=\"utf-8\") as file:\n",
    "            file.write(res.text)\n",
    "            lag = np.random.uniform(4,6)\n",
    "            print(f'Finished writing {year}, waiting ... {round(lag,2)}')\n",
    "            time.sleep(lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a9fab8dc-a51f-4ba9-9ce3-94daacd1f656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished scraping 1990\n",
      "Finished scraping 1991\n",
      "Finished scraping 1992\n",
      "Finished scraping 1993\n",
      "Finished scraping 1994\n",
      "Finished scraping 1995\n",
      "Finished scraping 1996\n",
      "Finished scraping 1997\n",
      "Finished scraping 1998\n",
      "Finished scraping 1999\n",
      "Finished scraping 2000\n",
      "Finished scraping 2001\n",
      "Finished scraping 2002\n",
      "Finished scraping 2003\n",
      "Finished scraping 2004\n",
      "Finished scraping 2005\n",
      "Finished scraping 2006\n",
      "Finished scraping 2007\n",
      "Finished scraping 2008\n",
      "Finished scraping 2009\n",
      "Finished scraping 2010\n",
      "Finished scraping 2011\n",
      "Finished scraping 2012\n",
      "Finished scraping 2013\n",
      "Finished scraping 2014\n",
      "Finished scraping 2015\n",
      "Finished scraping 2016\n",
      "Finished scraping 2017\n",
      "Finished scraping 2018\n",
      "Finished scraping 2019\n",
      "Finished scraping 2020\n",
      "Finished scraping 2021\n",
      "Finished scraping 2022\n"
     ]
    }
   ],
   "source": [
    "teamsal_all = []\n",
    "\n",
    "for year in years:\n",
    "    with open('webscraping/team/payroll/{}.html'.format(year), encoding=\"utf-8\") as file:\n",
    "        page = file.read()\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    teamsalary_table = soup.find(class_=\"hh-salaries-ranking-table\")\n",
    "    teamsalaries1 = pd.read_html(str(teamsalary_table))[0].drop(columns=\"Unnamed: 0\")    \n",
    "    teamsalaries1['Year'] = year\n",
    "    teamsalaries1.rename(columns={teamsalaries1.columns.tolist()[1]: 'Payroll',\n",
    "                              teamsalaries1.columns.tolist()[2]: 'Payroll_Adj'}, inplace=True)\n",
    "    \n",
    "    print(f'Finished scraping {year}')\n",
    "    teamsal_all.append(teamsalaries1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd87dd84-0c1b-464d-8b7f-b9edc2dfeda7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(966, 4)\n",
      "1990-2022\n"
     ]
    }
   ],
   "source": [
    "teamsalaries = pd.concat(teamsal_all)\n",
    "teamsalaries.to_csv('../data/team_payroll.csv', index=False)\n",
    "print(teamsalaries.shape)\n",
    "print(f'{teamsalaries.Year.min()}-{teamsalaries.Year.max()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcff0817-d15c-4b5c-a736-1bde84fc0fb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92e1baa-8a5c-4482-a41e-d37a4fb6e60c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b410a74-dbe0-4d5e-b410-be73ddb263a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faeb629f-6726-4ce7-b8c1-108e175169c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b613010-089f-4876-bb40-37a4acf17054",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839dc001-342e-44d7-9c3f-3e0347c3f5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing year + 1 because it is doing it by year the rankings came out (so for 2022-2023 season\n",
    "    # it says 2023 in the url, so in my list I have the year = the y - y+1 season, so here I need\n",
    "    # to specify y+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9619057d-c323-4fe6-b9ca-ebeb573387d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished writing 1990, waiting ... 5.45\n",
      "Finished writing 1991, waiting ... 5.1\n",
      "Finished writing 1992, waiting ... 4.57\n",
      "Finished writing 1993, waiting ... 5.03\n",
      "Finished writing 1994, waiting ... 5.69\n",
      "Finished writing 1995, waiting ... 5.31\n",
      "Finished writing 1996, waiting ... 4.55\n",
      "Finished writing 1997, waiting ... 5.23\n",
      "Finished writing 1998, waiting ... 5.28\n",
      "Finished writing 1999, waiting ... 4.49\n",
      "Finished writing 2000, waiting ... 5.5\n",
      "Finished writing 2001, waiting ... 5.35\n",
      "Finished writing 2002, waiting ... 4.46\n",
      "Finished writing 2003, waiting ... 5.55\n",
      "Finished writing 2004, waiting ... 4.44\n",
      "Finished writing 2005, waiting ... 4.35\n",
      "Finished writing 2006, waiting ... 4.54\n",
      "Finished writing 2007, waiting ... 4.95\n",
      "Finished writing 2008, waiting ... 4.22\n",
      "Finished writing 2009, waiting ... 4.37\n",
      "Finished writing 2010, waiting ... 4.24\n",
      "Finished writing 2011, waiting ... 4.1\n",
      "Finished writing 2012, waiting ... 4.65\n",
      "Finished writing 2013, waiting ... 4.54\n",
      "Finished writing 2014, waiting ... 4.73\n",
      "Finished writing 2015, waiting ... 4.28\n",
      "Finished writing 2016, waiting ... 5.13\n",
      "Finished writing 2017, waiting ... 5.9\n",
      "Finished writing 2018, waiting ... 4.63\n",
      "Finished writing 2019, waiting ... 5.88\n",
      "Finished writing 2020, waiting ... 5.58\n",
      "Finished writing 2021, waiting ... 5.18\n",
      "Finished writing 2022, waiting ... 4.78\n"
     ]
    }
   ],
   "source": [
    "for year in years:\n",
    "    url = f'https://www.basketball-reference.com/leagues/NBA_{year+1}_ratings.html'\n",
    "    res = requests.get(url)\n",
    "    if res.status_code >= 200:\n",
    "        with open(\"webscraping/team/rank/{}.html\".format(year), \"w+\", encoding=\"utf-8\") as file:\n",
    "            file.write(res.text)\n",
    "            lag = np.random.uniform(4,6)\n",
    "            print(f'Finished writing {year}, waiting ... {round(lag,2)}')\n",
    "            time.sleep(lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a07fccdb-394c-44ca-9176-c41f42aa9928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished scraping 1990\n",
      "Finished scraping 1991\n",
      "Finished scraping 1992\n",
      "Finished scraping 1993\n",
      "Finished scraping 1994\n",
      "Finished scraping 1995\n",
      "Finished scraping 1996\n",
      "Finished scraping 1997\n",
      "Finished scraping 1998\n",
      "Finished scraping 1999\n",
      "Finished scraping 2000\n",
      "Finished scraping 2001\n",
      "Finished scraping 2002\n",
      "Finished scraping 2003\n",
      "Finished scraping 2004\n",
      "Finished scraping 2005\n",
      "Finished scraping 2006\n",
      "Finished scraping 2007\n",
      "Finished scraping 2008\n",
      "Finished scraping 2009\n",
      "Finished scraping 2010\n",
      "Finished scraping 2011\n",
      "Finished scraping 2012\n",
      "Finished scraping 2013\n",
      "Finished scraping 2014\n",
      "Finished scraping 2015\n",
      "Finished scraping 2016\n",
      "Finished scraping 2017\n",
      "Finished scraping 2018\n",
      "Finished scraping 2019\n",
      "Finished scraping 2020\n",
      "Finished scraping 2021\n",
      "Finished scraping 2022\n"
     ]
    }
   ],
   "source": [
    "all = []\n",
    "\n",
    "for year in years:\n",
    "    with open('webscraping/team/rank/{}.html'.format(year), encoding=\"utf-8\") as file:\n",
    "        page = file.read()\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    table = soup.find('table',  {'id' : 'ratings'})\n",
    "    soup.find('tr', class_ = 'over_header').decompose()\n",
    "    df = pd.read_html(str(table))[0]  \n",
    "    df['Year'] = year\n",
    "    \n",
    "    print(f'Finished scraping {year}')\n",
    "    all.append(df)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f1290cb-c705-49d0-a2f5-bade44640c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(963, 16)\n",
      "1990-2022\n"
     ]
    }
   ],
   "source": [
    "team_rank = pd.concat(all)\n",
    "team_rank.to_csv('../data/team_rank.csv', index=False)\n",
    "print(team_rank.shape)\n",
    "print(f'{team_rank.Year.min()}-{team_rank.Year.max()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8eba7f-5b8d-4155-9ad3-15cb3b5add5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d44a1f-eead-40bf-aa40-517acd4c2592",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b60ffa-3aa9-4dca-a5f4-6590ddda4e03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec1cde7-5522-485b-915b-942d38080cab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3761cf9e-50d5-4d97-adef-ed1e4357a2b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a4bef5-3bbe-44ca-8601-f08c3ff9fe25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5dc925-2f74-4861-922b-5c1df947bcc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83e1335-f982-4190-bdfc-f439043eb35e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632100f8-56c1-4520-8e54-e5d87e53b5f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ddc793b5-fdf1-47c2-a9dc-f9134da46238",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Below we use the Selenium Python package to webscrape tables that are not static/pre-loaded and instead use JavaScript to render all rows of the table after the page has loaded.\n",
    "- if you want to run this on your own you need to\n",
    "    - save plug in to be local or save in AppData\n",
    "    - will need a diff webdriver if using something other than Edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a76ba84-f239-4094-8e71-2ccda374ebe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Edge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7e0d065f-b39e-49f3-8d12-2cb28557543d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = ['per_game', 'totals', 'advanced']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "88a7f150-1083-443b-9856-1c5972abad6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished writing 1990 per_game stats, waiting ... 4.23\n",
      "Finished writing 1991 per_game stats, waiting ... 4.63\n",
      "Finished writing 1992 per_game stats, waiting ... 4.65\n",
      "Finished writing 1993 per_game stats, waiting ... 4.75\n",
      "Finished writing 1994 per_game stats, waiting ... 4.52\n",
      "Finished writing 1995 per_game stats, waiting ... 4.18\n",
      "Finished writing 1996 per_game stats, waiting ... 5.06\n",
      "Finished writing 1997 per_game stats, waiting ... 4.73\n",
      "Finished writing 1998 per_game stats, waiting ... 5.98\n",
      "Finished writing 1999 per_game stats, waiting ... 5.28\n",
      "Finished writing 2000 per_game stats, waiting ... 4.95\n",
      "Finished writing 2001 per_game stats, waiting ... 5.98\n",
      "Finished writing 2002 per_game stats, waiting ... 5.79\n",
      "Finished writing 2003 per_game stats, waiting ... 5.83\n",
      "Finished writing 2004 per_game stats, waiting ... 5.64\n",
      "Finished writing 2005 per_game stats, waiting ... 4.12\n",
      "Finished writing 2006 per_game stats, waiting ... 5.98\n",
      "Finished writing 2007 per_game stats, waiting ... 4.78\n",
      "Finished writing 2008 per_game stats, waiting ... 4.66\n",
      "Finished writing 2009 per_game stats, waiting ... 5.27\n",
      "Finished writing 2010 per_game stats, waiting ... 4.55\n",
      "Finished writing 2011 per_game stats, waiting ... 5.42\n",
      "Finished writing 2012 per_game stats, waiting ... 5.11\n",
      "Finished writing 2013 per_game stats, waiting ... 5.42\n",
      "Finished writing 2014 per_game stats, waiting ... 5.5\n",
      "Finished writing 2015 per_game stats, waiting ... 4.16\n",
      "Finished writing 2016 per_game stats, waiting ... 5.76\n",
      "Finished writing 2017 per_game stats, waiting ... 5.22\n",
      "Finished writing 2018 per_game stats, waiting ... 4.84\n",
      "Finished writing 2019 per_game stats, waiting ... 5.32\n",
      "Finished writing 2020 per_game stats, waiting ... 4.72\n",
      "Finished writing 2021 per_game stats, waiting ... 4.67\n",
      "Finished writing 2022 per_game stats, waiting ... 4.87\n",
      "Finished writing 1990 totals stats, waiting ... 5.04\n",
      "Finished writing 1991 totals stats, waiting ... 5.63\n",
      "Finished writing 1992 totals stats, waiting ... 4.56\n",
      "Finished writing 1993 totals stats, waiting ... 5.86\n",
      "Finished writing 1994 totals stats, waiting ... 4.27\n",
      "Finished writing 1995 totals stats, waiting ... 4.1\n",
      "Finished writing 1996 totals stats, waiting ... 4.95\n",
      "Finished writing 1997 totals stats, waiting ... 4.6\n",
      "Finished writing 1998 totals stats, waiting ... 5.54\n",
      "Finished writing 1999 totals stats, waiting ... 4.09\n",
      "Finished writing 2000 totals stats, waiting ... 4.69\n",
      "Finished writing 2001 totals stats, waiting ... 4.62\n",
      "Finished writing 2002 totals stats, waiting ... 5.43\n",
      "Finished writing 2003 totals stats, waiting ... 4.3\n",
      "Finished writing 2004 totals stats, waiting ... 5.57\n",
      "Finished writing 2005 totals stats, waiting ... 4.08\n",
      "Finished writing 2006 totals stats, waiting ... 5.85\n",
      "Finished writing 2007 totals stats, waiting ... 5.65\n",
      "Finished writing 2008 totals stats, waiting ... 5.75\n",
      "Finished writing 2009 totals stats, waiting ... 5.84\n",
      "Finished writing 2010 totals stats, waiting ... 4.79\n",
      "Finished writing 2011 totals stats, waiting ... 5.38\n",
      "Finished writing 2012 totals stats, waiting ... 5.46\n",
      "Finished writing 2013 totals stats, waiting ... 5.52\n",
      "Finished writing 2014 totals stats, waiting ... 5.36\n",
      "Finished writing 2015 totals stats, waiting ... 4.69\n",
      "Finished writing 2016 totals stats, waiting ... 4.46\n",
      "Finished writing 2017 totals stats, waiting ... 5.74\n",
      "Finished writing 2018 totals stats, waiting ... 5.71\n",
      "Finished writing 2019 totals stats, waiting ... 5.98\n",
      "Finished writing 2020 totals stats, waiting ... 4.18\n",
      "Finished writing 2021 totals stats, waiting ... 5.22\n",
      "Finished writing 2022 totals stats, waiting ... 4.7\n",
      "Finished writing 1990 advanced stats, waiting ... 5.89\n",
      "Finished writing 1991 advanced stats, waiting ... 4.58\n",
      "Finished writing 1992 advanced stats, waiting ... 5.6\n",
      "Finished writing 1993 advanced stats, waiting ... 4.37\n",
      "Finished writing 1994 advanced stats, waiting ... 5.06\n",
      "Finished writing 1995 advanced stats, waiting ... 4.44\n",
      "Finished writing 1996 advanced stats, waiting ... 5.0\n",
      "Finished writing 1997 advanced stats, waiting ... 4.36\n",
      "Finished writing 1998 advanced stats, waiting ... 5.86\n",
      "Finished writing 1999 advanced stats, waiting ... 5.63\n",
      "Finished writing 2000 advanced stats, waiting ... 4.96\n",
      "Finished writing 2001 advanced stats, waiting ... 5.01\n",
      "Finished writing 2002 advanced stats, waiting ... 5.38\n",
      "Finished writing 2003 advanced stats, waiting ... 4.24\n",
      "Finished writing 2004 advanced stats, waiting ... 5.37\n",
      "Finished writing 2005 advanced stats, waiting ... 5.88\n",
      "Finished writing 2006 advanced stats, waiting ... 4.68\n",
      "Finished writing 2007 advanced stats, waiting ... 4.73\n",
      "Finished writing 2008 advanced stats, waiting ... 4.51\n",
      "Finished writing 2009 advanced stats, waiting ... 4.61\n",
      "Finished writing 2010 advanced stats, waiting ... 4.76\n",
      "Finished writing 2011 advanced stats, waiting ... 5.91\n",
      "Finished writing 2012 advanced stats, waiting ... 5.11\n",
      "Finished writing 2013 advanced stats, waiting ... 4.89\n",
      "Finished writing 2014 advanced stats, waiting ... 5.2\n",
      "Finished writing 2015 advanced stats, waiting ... 5.36\n",
      "Finished writing 2016 advanced stats, waiting ... 4.38\n",
      "Finished writing 2017 advanced stats, waiting ... 4.85\n",
      "Finished writing 2018 advanced stats, waiting ... 5.7\n",
      "Finished writing 2019 advanced stats, waiting ... 4.09\n",
      "Finished writing 2020 advanced stats, waiting ... 4.26\n",
      "Finished writing 2021 advanced stats, waiting ... 5.14\n",
      "Finished writing 2022 advanced stats, waiting ... 4.43\n"
     ]
    }
   ],
   "source": [
    "for stat in stats:\n",
    "    for year in years:\n",
    "        url = f'https://www.basketball-reference.com/leagues/NBA_{year+1}_{stat}.html'\n",
    "        driver.get(url)\n",
    "        driver.execute_script('window.scrollTo(1,10000)')\n",
    "        html = driver.page_source\n",
    "\n",
    "        with open(f'webscraping/players/{stat}/{year}.html', \"w+\", encoding=\"utf-8\") as file:\n",
    "            file.write(html)\n",
    "        lag = np.random.uniform(4,6)\n",
    "        print(f'Finished writing {year} {stat} stats, waiting ... {round(lag,2)}')\n",
    "        time.sleep(lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "92858e68-3b81-4fe8-aaec-fe749fcf45f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished scraping 1990 per_game stats\n",
      "Finished scraping 1991 per_game stats\n",
      "Finished scraping 1992 per_game stats\n",
      "Finished scraping 1993 per_game stats\n",
      "Finished scraping 1994 per_game stats\n",
      "Finished scraping 1995 per_game stats\n",
      "Finished scraping 1996 per_game stats\n",
      "Finished scraping 1997 per_game stats\n",
      "Finished scraping 1998 per_game stats\n",
      "Finished scraping 1999 per_game stats\n",
      "Finished scraping 2000 per_game stats\n",
      "Finished scraping 2001 per_game stats\n",
      "Finished scraping 2002 per_game stats\n",
      "Finished scraping 2003 per_game stats\n",
      "Finished scraping 2004 per_game stats\n",
      "Finished scraping 2005 per_game stats\n",
      "Finished scraping 2006 per_game stats\n",
      "Finished scraping 2007 per_game stats\n",
      "Finished scraping 2008 per_game stats\n",
      "Finished scraping 2009 per_game stats\n",
      "Finished scraping 2010 per_game stats\n",
      "Finished scraping 2011 per_game stats\n",
      "Finished scraping 2012 per_game stats\n",
      "Finished scraping 2013 per_game stats\n",
      "Finished scraping 2014 per_game stats\n",
      "Finished scraping 2015 per_game stats\n",
      "Finished scraping 2016 per_game stats\n",
      "Finished scraping 2017 per_game stats\n",
      "Finished scraping 2018 per_game stats\n",
      "Finished scraping 2019 per_game stats\n",
      "Finished scraping 2020 per_game stats\n",
      "Finished scraping 2021 per_game stats\n",
      "Finished scraping 2022 per_game stats\n",
      "Finished scraping 1990 totals stats\n",
      "Finished scraping 1991 totals stats\n",
      "Finished scraping 1992 totals stats\n",
      "Finished scraping 1993 totals stats\n",
      "Finished scraping 1994 totals stats\n",
      "Finished scraping 1995 totals stats\n",
      "Finished scraping 1996 totals stats\n",
      "Finished scraping 1997 totals stats\n",
      "Finished scraping 1998 totals stats\n",
      "Finished scraping 1999 totals stats\n",
      "Finished scraping 2000 totals stats\n",
      "Finished scraping 2001 totals stats\n",
      "Finished scraping 2002 totals stats\n",
      "Finished scraping 2003 totals stats\n",
      "Finished scraping 2004 totals stats\n",
      "Finished scraping 2005 totals stats\n",
      "Finished scraping 2006 totals stats\n",
      "Finished scraping 2007 totals stats\n",
      "Finished scraping 2008 totals stats\n",
      "Finished scraping 2009 totals stats\n",
      "Finished scraping 2010 totals stats\n",
      "Finished scraping 2011 totals stats\n",
      "Finished scraping 2012 totals stats\n",
      "Finished scraping 2013 totals stats\n",
      "Finished scraping 2014 totals stats\n",
      "Finished scraping 2015 totals stats\n",
      "Finished scraping 2016 totals stats\n",
      "Finished scraping 2017 totals stats\n",
      "Finished scraping 2018 totals stats\n",
      "Finished scraping 2019 totals stats\n",
      "Finished scraping 2020 totals stats\n",
      "Finished scraping 2021 totals stats\n",
      "Finished scraping 2022 totals stats\n",
      "Finished scraping 1990 advanced stats\n",
      "Finished scraping 1991 advanced stats\n",
      "Finished scraping 1992 advanced stats\n",
      "Finished scraping 1993 advanced stats\n",
      "Finished scraping 1994 advanced stats\n",
      "Finished scraping 1995 advanced stats\n",
      "Finished scraping 1996 advanced stats\n",
      "Finished scraping 1997 advanced stats\n",
      "Finished scraping 1998 advanced stats\n",
      "Finished scraping 1999 advanced stats\n",
      "Finished scraping 2000 advanced stats\n",
      "Finished scraping 2001 advanced stats\n",
      "Finished scraping 2002 advanced stats\n",
      "Finished scraping 2003 advanced stats\n",
      "Finished scraping 2004 advanced stats\n",
      "Finished scraping 2005 advanced stats\n",
      "Finished scraping 2006 advanced stats\n",
      "Finished scraping 2007 advanced stats\n",
      "Finished scraping 2008 advanced stats\n",
      "Finished scraping 2009 advanced stats\n",
      "Finished scraping 2010 advanced stats\n",
      "Finished scraping 2011 advanced stats\n",
      "Finished scraping 2012 advanced stats\n",
      "Finished scraping 2013 advanced stats\n",
      "Finished scraping 2014 advanced stats\n",
      "Finished scraping 2015 advanced stats\n",
      "Finished scraping 2016 advanced stats\n",
      "Finished scraping 2017 advanced stats\n",
      "Finished scraping 2018 advanced stats\n",
      "Finished scraping 2019 advanced stats\n",
      "Finished scraping 2020 advanced stats\n",
      "Finished scraping 2021 advanced stats\n",
      "Finished scraping 2022 advanced stats\n"
     ]
    }
   ],
   "source": [
    "pg_all = []\n",
    "tot_all = []\n",
    "adv_all = []\n",
    "\n",
    "for stat in stats:\n",
    "    for year in years:  \n",
    "        with open(f'webscraping/players/{stat}/{year}.html', encoding=\"utf-8\") as file:\n",
    "            page = file.read()\n",
    "        soup = BeautifulSoup(page, 'html.parser')\n",
    "        table = soup.find('table', {'id' : f'{stat}_stats'})\n",
    "        soup.find('tr', class_ = 'thead').decompose()\n",
    "        df = pd.read_html(str(table))[0] \n",
    "        df['Year'] = year\n",
    "        df['Stat'] = stat\n",
    "        \n",
    "        print(f'Finished scraping {year} {stat} stats')\n",
    "        \n",
    "        if stat == 'per_game':\n",
    "            pg_all.append(df)\n",
    "        if stat == 'totals':\n",
    "            tot_all.append(df)\n",
    "        if stat == 'advanced':\n",
    "            adv_all.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "34161333-32cd-4e70-9a04-28f43bab485d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --- Per Game ---\n",
      "(19362, 32)\n",
      "1990-2022\n",
      "\n",
      " --- Totals ---\n",
      "(19362, 32)\n",
      "1990-2022\n",
      "\n",
      " --- Advanced ---\n",
      "(19362, 31)\n",
      "1990-2022\n"
     ]
    }
   ],
   "source": [
    "pg = pd.concat(pg_all)\n",
    "pg.to_csv('../data/per_game_data.csv', index=False)\n",
    "print(f' --- Per Game ---')\n",
    "print(pg.shape)\n",
    "print(f'{pg.Year.min()}-{pg.Year.max()}')\n",
    "\n",
    "tot = pd.concat(tot_all)\n",
    "tot.to_csv('../data/totals_data.csv', index=False)\n",
    "print(f'\\n --- Totals ---')\n",
    "print(tot.shape)\n",
    "print(f'{tot.Year.min()}-{tot.Year.max()}')\n",
    "\n",
    "adv = pd.concat(adv_all)\n",
    "adv.to_csv('../data/advanced_data.csv', index=False)\n",
    "print(f'\\n --- Advanced ---')\n",
    "print(adv.shape)\n",
    "print(f'{adv.Year.min()}-{adv.Year.max()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7178867c-5d9e-4e89-aee7-388747c4add2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rk</th>\n",
       "      <th>Player</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tm</th>\n",
       "      <th>G</th>\n",
       "      <th>GS</th>\n",
       "      <th>MP</th>\n",
       "      <th>FG</th>\n",
       "      <th>FGA</th>\n",
       "      <th>...</th>\n",
       "      <th>DRB</th>\n",
       "      <th>TRB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PF</th>\n",
       "      <th>PTS</th>\n",
       "      <th>Year</th>\n",
       "      <th>Stat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Mark Acres</td>\n",
       "      <td>C</td>\n",
       "      <td>27</td>\n",
       "      <td>ORL</td>\n",
       "      <td>80</td>\n",
       "      <td>50</td>\n",
       "      <td>21.1</td>\n",
       "      <td>1.7</td>\n",
       "      <td>3.6</td>\n",
       "      <td>...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1990</td>\n",
       "      <td>per_game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Michael Adams</td>\n",
       "      <td>PG</td>\n",
       "      <td>27</td>\n",
       "      <td>DEN</td>\n",
       "      <td>79</td>\n",
       "      <td>74</td>\n",
       "      <td>34.1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>...</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>15.5</td>\n",
       "      <td>1990</td>\n",
       "      <td>per_game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Mark Aguirre</td>\n",
       "      <td>SF</td>\n",
       "      <td>30</td>\n",
       "      <td>DET</td>\n",
       "      <td>78</td>\n",
       "      <td>40</td>\n",
       "      <td>25.7</td>\n",
       "      <td>5.6</td>\n",
       "      <td>11.5</td>\n",
       "      <td>...</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.6</td>\n",
       "      <td>14.1</td>\n",
       "      <td>1990</td>\n",
       "      <td>per_game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Danny Ainge</td>\n",
       "      <td>PG</td>\n",
       "      <td>30</td>\n",
       "      <td>SAC</td>\n",
       "      <td>75</td>\n",
       "      <td>68</td>\n",
       "      <td>36.4</td>\n",
       "      <td>6.7</td>\n",
       "      <td>15.4</td>\n",
       "      <td>...</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>17.9</td>\n",
       "      <td>1990</td>\n",
       "      <td>per_game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Mark Alarie</td>\n",
       "      <td>PF</td>\n",
       "      <td>26</td>\n",
       "      <td>WSB</td>\n",
       "      <td>82</td>\n",
       "      <td>10</td>\n",
       "      <td>23.1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.6</td>\n",
       "      <td>...</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.7</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1990</td>\n",
       "      <td>per_game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>601</td>\n",
       "      <td>Thaddeus Young</td>\n",
       "      <td>PF</td>\n",
       "      <td>33</td>\n",
       "      <td>TOR</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>18.3</td>\n",
       "      <td>2.6</td>\n",
       "      <td>5.5</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2022</td>\n",
       "      <td>per_game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>602</td>\n",
       "      <td>Trae Young</td>\n",
       "      <td>PG</td>\n",
       "      <td>23</td>\n",
       "      <td>ATL</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>34.9</td>\n",
       "      <td>9.4</td>\n",
       "      <td>20.3</td>\n",
       "      <td>...</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>9.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>28.4</td>\n",
       "      <td>2022</td>\n",
       "      <td>per_game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>603</td>\n",
       "      <td>Omer Yurtseven</td>\n",
       "      <td>C</td>\n",
       "      <td>23</td>\n",
       "      <td>MIA</td>\n",
       "      <td>56</td>\n",
       "      <td>12</td>\n",
       "      <td>12.6</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.4</td>\n",
       "      <td>...</td>\n",
       "      <td>3.7</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2022</td>\n",
       "      <td>per_game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>604</td>\n",
       "      <td>Cody Zeller</td>\n",
       "      <td>C</td>\n",
       "      <td>29</td>\n",
       "      <td>POR</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>3.3</td>\n",
       "      <td>...</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2022</td>\n",
       "      <td>per_game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>605</td>\n",
       "      <td>Ivica Zubac</td>\n",
       "      <td>C</td>\n",
       "      <td>24</td>\n",
       "      <td>LAC</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>24.4</td>\n",
       "      <td>4.1</td>\n",
       "      <td>6.5</td>\n",
       "      <td>...</td>\n",
       "      <td>5.6</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.7</td>\n",
       "      <td>10.3</td>\n",
       "      <td>2022</td>\n",
       "      <td>per_game</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19362 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Rk          Player Pos Age   Tm   G  GS    MP   FG   FGA  ...  DRB  TRB  \\\n",
       "0      1      Mark Acres   C  27  ORL  80  50  21.1  1.7   3.6  ...  3.5  5.4   \n",
       "1      2   Michael Adams  PG  27  DEN  79  74  34.1  5.0  12.5  ...  2.2  2.8   \n",
       "2      3    Mark Aguirre  SF  30  DET  78  40  25.7  5.6  11.5  ...  2.4  3.9   \n",
       "3      4     Danny Ainge  PG  30  SAC  75  68  36.4  6.7  15.4  ...  3.4  4.3   \n",
       "4      5     Mark Alarie  PF  26  WSB  82  10  23.1  4.5   9.6  ...  2.7  4.6   \n",
       "..   ...             ...  ..  ..  ...  ..  ..   ...  ...   ...  ...  ...  ...   \n",
       "836  601  Thaddeus Young  PF  33  TOR  26   0  18.3  2.6   5.5  ...  2.9  4.4   \n",
       "837  602      Trae Young  PG  23  ATL  76  76  34.9  9.4  20.3  ...  3.1  3.7   \n",
       "838  603  Omer Yurtseven   C  23  MIA  56  12  12.6  2.3   4.4  ...  3.7  5.3   \n",
       "839  604     Cody Zeller   C  29  POR  27   0  13.1  1.9   3.3  ...  2.8  4.6   \n",
       "840  605     Ivica Zubac   C  24  LAC  76  76  24.4  4.1   6.5  ...  5.6  8.5   \n",
       "\n",
       "     AST  STL  BLK  TOV   PF   PTS  Year      Stat  \n",
       "0    0.8  0.5  0.3  0.9  3.1   4.5  1990  per_game  \n",
       "1    6.3  1.5  0.0  1.8  1.7  15.5  1990  per_game  \n",
       "2    1.9  0.4  0.2  1.6  2.6  14.1  1990  per_game  \n",
       "3    6.0  1.5  0.2  2.5  3.2  17.9  1990  per_game  \n",
       "4    1.7  0.7  0.5  1.2  2.7  10.5  1990  per_game  \n",
       "..   ...  ...  ...  ...  ...   ...   ...       ...  \n",
       "836  1.7  1.2  0.4  0.8  1.7   6.3  2022  per_game  \n",
       "837  9.7  0.9  0.1  4.0  1.7  28.4  2022  per_game  \n",
       "838  0.9  0.3  0.4  0.7  1.5   5.3  2022  per_game  \n",
       "839  0.8  0.3  0.2  0.7  2.1   5.2  2022  per_game  \n",
       "840  1.6  0.5  1.0  1.5  2.7  10.3  2022  per_game  \n",
       "\n",
       "[19362 rows x 32 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccd78db-e393-4035-a5e4-d67f4c7d039d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fc61b76-4fec-4172-95d1-0de031991586",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.basketball-reference.com/contracts/salary-cap-history.html'\n",
    "driver.get(url)\n",
    "driver.execute_script('window.scrollTo(1,10000)')\n",
    "html = driver.page_source\n",
    "\n",
    "with open('webscraping/salary/salarycap/salarycap.html', \"w+\", encoding=\"utf-8\") as file:\n",
    "    file.write(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3fd651c-1b65-4282-afc0-7133154c8c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('webscraping/salary/salarycap/salarycap.html', encoding=\"utf-8\") as file:\n",
    "    page = file.read()\n",
    "soup = BeautifulSoup(page, 'html.parser')\n",
    "table = soup.find('table', {'id' : 'salary_cap_history'})\n",
    "salarycap = pd.read_html(str(table))[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad871adc-78c2-44b9-81ce-90a9e3eb508f",
   "metadata": {},
   "outputs": [],
   "source": [
    "salarycap\n",
    "salarycap.to_csv('../data/salarycap.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a157b3c-6a3a-4baa-86bd-33b77cc10fb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbb928e-0b7a-4c07-8b8b-4ce396f65869",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25d8e33-e905-4c82-b76f-dc52f2c3b9d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4f9a30-1beb-4f60-9842-058e67adc9d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9f17c0-e101-4510-93c2-4ad13641fa9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "50a62451-fb51-41cf-a676-fb4ca430d71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Edge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ebc2c6d6-d640-4200-860b-b3555ee72589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALL NBA TEAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "aef1cb5a-17c7-4fc9-97f6-a2efbba67826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished writing 1990, waiting ... 4.2\n",
      "Finished writing 1991, waiting ... 4.77\n",
      "Finished writing 1992, waiting ... 5.02\n",
      "Finished writing 1993, waiting ... 4.91\n",
      "Finished writing 1994, waiting ... 4.19\n",
      "Finished writing 1995, waiting ... 4.94\n",
      "Finished writing 1996, waiting ... 5.23\n",
      "Finished writing 1997, waiting ... 4.07\n",
      "Finished writing 1998, waiting ... 5.5\n",
      "Finished writing 1999, waiting ... 5.91\n",
      "Finished writing 2000, waiting ... 5.72\n",
      "Finished writing 2001, waiting ... 4.69\n",
      "Finished writing 2002, waiting ... 4.91\n",
      "Finished writing 2003, waiting ... 5.77\n",
      "Finished writing 2004, waiting ... 4.43\n",
      "Finished writing 2005, waiting ... 5.03\n",
      "Finished writing 2006, waiting ... 5.52\n",
      "Finished writing 2007, waiting ... 5.45\n",
      "Finished writing 2008, waiting ... 5.37\n",
      "Finished writing 2009, waiting ... 4.78\n",
      "Finished writing 2010, waiting ... 5.88\n",
      "Finished writing 2011, waiting ... 5.33\n",
      "Finished writing 2012, waiting ... 4.96\n",
      "Finished writing 2013, waiting ... 4.12\n",
      "Finished writing 2014, waiting ... 4.51\n",
      "Finished writing 2015, waiting ... 5.04\n",
      "Finished writing 2016, waiting ... 4.68\n",
      "Finished writing 2017, waiting ... 4.77\n",
      "Finished writing 2018, waiting ... 4.35\n",
      "Finished writing 2019, waiting ... 4.42\n",
      "Finished writing 2020, waiting ... 4.18\n",
      "Finished writing 2021, waiting ... 5.4\n",
      "Finished writing 2022, waiting ... 5.96\n"
     ]
    }
   ],
   "source": [
    "for year in years:\n",
    "    url = f'https://www.basketball-reference.com/awards/awards_{year+1}.html'\n",
    "    driver.get(url)\n",
    "    driver.execute_script('window.scrollTo(1,10000)')\n",
    "    html = driver.page_source\n",
    "\n",
    "    with open(f'webscraping/players/all_team/{year}.html', \"w+\", encoding=\"utf-8\") as file:\n",
    "        file.write(html)\n",
    "    lag = np.random.uniform(4,6)\n",
    "    print(f'Finished writing {year}, waiting ... {round(lag,2)}')\n",
    "    time.sleep(lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a80b27c6-ea7b-4992-8d23-73b71f854ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished scraping 1990\n",
      "Finished scraping 1991\n",
      "Finished scraping 1992\n",
      "Finished scraping 1993\n",
      "Finished scraping 1994\n",
      "Finished scraping 1995\n",
      "Finished scraping 1996\n",
      "Finished scraping 1997\n",
      "Finished scraping 1998\n",
      "Finished scraping 1999\n",
      "Finished scraping 2000\n",
      "Finished scraping 2001\n",
      "Finished scraping 2002\n",
      "Finished scraping 2003\n",
      "Finished scraping 2004\n",
      "Finished scraping 2005\n",
      "Finished scraping 2006\n",
      "Finished scraping 2007\n",
      "Finished scraping 2008\n",
      "Finished scraping 2009\n",
      "Finished scraping 2010\n",
      "Finished scraping 2011\n",
      "Finished scraping 2012\n",
      "Finished scraping 2013\n",
      "Finished scraping 2014\n",
      "Finished scraping 2015\n",
      "Finished scraping 2016\n",
      "Finished scraping 2017\n",
      "Finished scraping 2018\n",
      "Finished scraping 2019\n",
      "Finished scraping 2020\n",
      "Finished scraping 2021\n",
      "Finished scraping 2022\n"
     ]
    }
   ],
   "source": [
    "all = []\n",
    "\n",
    "for year in years:  \n",
    "    with open(f'webscraping/players/all_team/{year}.html', encoding=\"utf-8\") as file:\n",
    "        page = file.read()\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    table = soup.find('table', {'id' : 'leading_all_nba'})\n",
    "    try:\n",
    "        soup.find('tr', class_ = 'over_header').decompose()\n",
    "        soup.find('tr', {'id' : 'start_2nd'}).decompose()\n",
    "        soup.find('tr', {'id' : 'start_3rd'}).decompose()\n",
    "        soup.find('tr', {'id' : 'start_ORV'}).decompose()\n",
    "        soup.find('div', class_ = 'topscroll_div').decompose()\n",
    "    except:\n",
    "        soup.find('tr', class_ = 'over_header').decompose()\n",
    "        soup.find('tr', {'id' : 'start_1T'}).decompose()\n",
    "        soup.find('tr', {'id' : 'start_2T'}).decompose()\n",
    "        soup.find('tr', {'id' : 'start_3T'}).decompose()\n",
    "        soup.find('tr', {'id' : 'start_ORV'}).decompose()\n",
    "        soup.find('div', class_ = 'topscroll_div').decompose()\n",
    "               \n",
    "    df = pd.read_html(str(table), header=1)[0] \n",
    "    df['Year'] = year   \n",
    "    \n",
    "    print(f'Finished scraping {year}')\n",
    "    all.append(df)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1cc812ce-f9d2-45b4-8ea3-35d3ae6476a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1354, 24)\n",
      "1990-2022\n"
     ]
    }
   ],
   "source": [
    "all_nba = pd.concat(all)\n",
    "all_nba.to_csv('../data/all_nba_teams.csv', index=False)\n",
    "print(all_nba.shape)\n",
    "print(f'{all_nba.Year.min()}-{all_nba.Year.max()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5291154c-e84d-4c91-b4f5-a5d79b4f29de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea4fb67-1fa4-42c3-a121-5b494bf63e8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8658914-36ba-416a-8e3a-120630281d3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9257e0a8-6729-4b53-8e24-8933501daf23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1954da-4734-40c4-ab10-0701e5034e15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1c1d12-228a-4fdf-a31b-260bbbba7f95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2ab703-d5dc-4aa0-8d83-993fb0174993",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b8a542-d77c-4ce2-b6a0-427c29c0f456",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebfb431-4967-4e99-ab96-a5eb8536daad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALL STAR APPEARANCES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "41ff2726-0654-4618-b193-405eb4a7195e",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/List_of_NBA_All-Stars'\n",
    "res = requests.get(url)\n",
    "if res.status_code >= 200:\n",
    "    soup = BeautifulSoup(res.content, 'lxml')\n",
    "    table = soup.find('table', class_=\"wikitable sortable\")\n",
    "    \n",
    "    as_appearance = pd.read_html(str(table))[0]\n",
    "\n",
    "as_appearance.to_csv('../data/all_star_appearances.csv', index=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b335beef-acfc-4a9d-bda0-53419c86bfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sal_all = []\n",
    "\n",
    "for year in years:\n",
    "    with open('webscraping/salary/{}.html'.format(year), encoding=\"utf-8\") as file:\n",
    "        page = file.read()\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    salary_table = soup.find(class_=\"hh-salaries-ranking-table\")\n",
    "    salaries1 = pd.read_html(str(salary_table))[0].drop(columns=\"Unnamed: 0\")    \n",
    "    salaries1['Year'] = year\n",
    "    salaries1.rename(columns={salaries1.columns.tolist()[1]: 'Salary',\n",
    "                              salaries1.columns.tolist()[2]: 'Salary_Adj'}, inplace=True)\n",
    "    \n",
    "    print(f'Finished scraping {year}')\n",
    "    sal_all.append(salaries1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237c2bf2-4042-4c76-8f8e-e1023fbb4468",
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries = pd.concat(sal_all)\n",
    "salaries.to_csv('../data/salaries.csv', index=False)\n",
    "print(salaries.shape)\n",
    "print(f'{salaries.Year.min()}-{salaries.Year.max()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0c624a-7ba8-4341-b16e-4277c715673b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b578e4-4cdf-4613-b1e3-fea06b3aa4c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31b380d-d1fd-414d-a84a-fa30dc93ebbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e399087a-8165-4fa6-a65a-364971f5fa96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868759d5-1f9f-4403-8332-e2922fe2b333",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
